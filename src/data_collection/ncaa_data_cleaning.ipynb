{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Clean and organising the raw data scraped from https://stats.ncaa.org/\n",
    "\n",
    "Author: Atharv Sonwane (Player & Team Data Cleaning) & Vedant Shah (Cleaning team_stats & Combining yearwise data)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from tqdm import tnrange\n",
    "import shutil"
   ]
  },
  {
   "source": [
    "# Clean Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:3: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Cleaning data', max=334.0, style=ProgressStyle(descriptio…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5393361c793e435c9daf1dedfa7aa476"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "UMBC (America East).csv\n",
      "Seton Hall (Big East).csv\n",
      "Florida (SEC).csv\n",
      "NJIT (ASUN).csv\n",
      "Navy (Patriot).csv\n",
      "Wisconsin (Big Ten).csv\n",
      "Northern Ill. (MAC).csv\n",
      "Mercer (SoCon).csv\n",
      "UNLV (MWC).csv\n",
      "La.-Monroe (Sun Belt).csv\n",
      "Stony Brook (America East).csv\n",
      "UConn (AAC).csv\n",
      "South Fla. (AAC).csv\n",
      "Winthrop (Big South).csv\n",
      "Purdue Fort Wayne (Summit League).csv\n",
      "Brown (Ivy League).csv\n",
      "UC Riverside (Big West).csv\n",
      "Charlotte (C-USA).csv\n",
      "Northern Ariz. (Big Sky).csv\n",
      "Cleveland St. (Horizon).csv\n",
      "Samford (SoCon).csv\n",
      "UNCW (CAA).csv\n",
      "East Carolina (AAC).csv\n",
      "Indiana St. (MVC).csv\n",
      "Binghamton (America East).csv\n",
      "UTRGV (WAC).csv\n",
      "N.C. A&T (MEAC).csv\n",
      "Northwestern (Big Ten).csv\n",
      "Green Bay (Horizon).csv\n",
      "Oklahoma (Big 12).csv\n",
      "UMES (MEAC).csv\n",
      "CSUN (Big West).csv\n",
      "Fairleigh Dickinson (NEC).csv\n",
      "Santa Clara (WCC).csv\n",
      "DePaul (Big East).csv\n",
      "Saint Peter's (MAAC).csv\n",
      "Sacramento St. (Big Sky).csv\n",
      "Saint Francis (PA) (NEC).csv\n",
      "Cornell (Ivy League).csv\n",
      "Sacred Heart (NEC).csv\n",
      "UTSA (C-USA).csv\n",
      "Central Conn. St. (NEC).csv\n",
      "Southern Utah (Big Sky).csv\n",
      "Boston College (ACC).csv\n",
      "Purdue (Big Ten).csv\n",
      "Pepperdine (WCC).csv\n",
      "LSU (SEC).csv\n",
      "Louisville (ACC).csv\n",
      "LIU Brooklyn (NEC).csv\n",
      "Syracuse (ACC).csv\n",
      "Miami (OH) (MAC).csv\n",
      "New Mexico St. (WAC).csv\n",
      "Houston (AAC).csv\n",
      "Middle Tenn. (C-USA).csv\n",
      "Jacksonville St. (OVC).csv\n",
      "Charleston So. (Big South).csv\n",
      "James Madison (CAA).csv\n",
      "Western Caro. (SoCon).csv\n",
      "Air Force (MWC).csv\n",
      "Oregon (Pac-12).csv\n",
      "Sam Houston St. (Southland).csv\n",
      "Norfolk St. (MEAC).csv\n",
      "Washington St. (Pac-12).csv\n",
      "FGCU (ASUN).csv\n",
      "Delaware St. (MEAC).csv\n",
      "Providence (Big East).csv\n",
      "Idaho (Big Sky).csv\n",
      "Texas Tech (Big 12).csv\n",
      "Albany (NY) (America East).csv\n",
      "Missouri (SEC).csv\n",
      "St. Francis Brooklyn (NEC).csv\n",
      "TCU (Big 12).csv\n",
      "Eastern Wash. (Big Sky).csv\n",
      "Montana (Big Sky).csv\n",
      "South Alabama (Sun Belt).csv\n",
      "Western Ky. (C-USA).csv\n",
      "Loyola Chicago (MVC).csv\n",
      "St. John's (NY) (Big East).csv\n",
      "Michigan (Big Ten).csv\n",
      "Fla. Atlantic (C-USA).csv\n",
      "UC Davis (Big West).csv\n",
      "Georgia (SEC).csv\n",
      "Penn (Ivy League).csv\n",
      "Michigan St. (Big Ten).csv\n",
      "Kennesaw St. (ASUN).csv\n",
      "Creighton (Big East).csv\n",
      "Southern California (Pac-12).csv\n",
      "North Dakota (Summit League).csv\n",
      "Quinnipiac (MAAC).csv\n",
      "Arkansas (SEC).csv\n",
      "SFA (Southland).csv\n",
      "Yale (Ivy League).csv\n",
      "Cincinnati (AAC).csv\n",
      "UNC Asheville (Big South).csv\n",
      "UCF (AAC).csv\n",
      "Alcorn (SWAC).csv\n",
      "Wake Forest (ACC).csv\n",
      "Kentucky (SEC).csv\n",
      "Northern Ky. (Horizon).csv\n",
      "Weber St. (Big Sky).csv\n",
      "Long Beach St. (Big West).csv\n",
      "Tulsa (AAC).csv\n",
      "Fresno St. (MWC).csv\n",
      "Memphis (AAC).csv\n",
      "Boise St. (MWC).csv\n",
      "Northeastern (CAA).csv\n",
      "Virginia (ACC).csv\n",
      "Arizona (Pac-12).csv\n",
      "Utah St. (MWC).csv\n",
      "Florida St. (ACC).csv\n",
      "Arizona St. (Pac-12).csv\n",
      "Saint Louis (Atlantic 10).csv\n",
      "Princeton (Ivy League).csv\n",
      "Alabama St. (SWAC).csv\n",
      "Manhattan (MAAC).csv\n",
      "Saint Mary's (CA) (WCC).csv\n",
      "Nevada (MWC).csv\n",
      "Siena (MAAC).csv\n",
      "Abilene Christian (Southland).csv\n",
      "Belmont (OVC).csv\n",
      "Northern Colo. (Big Sky).csv\n",
      "Coastal Caro. (Sun Belt).csv\n",
      "Little Rock (Sun Belt).csv\n",
      "Kent St. (MAC).csv\n",
      "Wright St. (Horizon).csv\n",
      "Coppin St. (MEAC).csv\n",
      "Jackson St. (SWAC).csv\n",
      "Liberty (ASUN).csv\n",
      "Ark.-Pine Bluff (SWAC).csv\n",
      "William & Mary (CAA).csv\n",
      "USC Upstate (Big South).csv\n",
      "Miami (FL) (ACC).csv\n",
      "Washington (Pac-12).csv\n",
      "Mississippi St. (SEC).csv\n",
      "Texas (Big 12).csv\n",
      "Wyoming (MWC).csv\n",
      "Portland (WCC).csv\n",
      "Texas Southern (SWAC).csv\n",
      "Iowa St. (Big 12).csv\n",
      "Bradley (MVC).csv\n",
      "NC State (ACC).csv\n",
      "Tennessee St. (OVC).csv\n",
      "Canisius (MAAC).csv\n",
      "New Hampshire (America East).csv\n",
      "American (Patriot).csv\n",
      "Southeast Mo. St. (OVC).csv\n",
      "Eastern Ill. (OVC).csv\n",
      "Southern Miss. (C-USA).csv\n",
      "Lipscomb (ASUN).csv\n",
      "Houston Baptist (Southland).csv\n",
      "Duquesne (Atlantic 10).csv\n",
      "SIUE (OVC).csv\n",
      "Mississippi Val. (SWAC).csv\n",
      "Colorado St. (MWC).csv\n",
      "North Texas (C-USA).csv\n",
      "San Diego St. (MWC).csv\n",
      "Valparaiso (MVC).csv\n",
      "Dartmouth (Ivy League).csv\n",
      "Tennessee Tech (OVC).csv\n",
      "Delaware (CAA).csv\n",
      "Colgate (Patriot).csv\n",
      "Incarnate Word (Southland).csv\n",
      "Omaha (Summit League).csv\n",
      "Ga. Southern (Sun Belt).csv\n",
      "Iowa (Big Ten).csv\n",
      "Kansas (Big 12).csv\n",
      "South Carolina (SEC).csv\n",
      "New Mexico (MWC).csv\n",
      "Illinois (Big Ten).csv\n",
      "Villanova (Big East).csv\n",
      "George Mason (Atlantic 10).csv\n",
      "Marquette (Big East).csv\n",
      "Louisiana Tech (C-USA).csv\n",
      "Arkansas St. (Sun Belt).csv\n",
      "Bryant (NEC).csv\n",
      "UAB (C-USA).csv\n",
      "Lafayette (Patriot).csv\n",
      "Bethune-Cookman (MEAC).csv\n",
      "Tulane (AAC).csv\n",
      "Presbyterian (Big South).csv\n",
      "Oakland (Horizon).csv\n",
      "Western Mich. (MAC).csv\n",
      "Rice (C-USA).csv\n",
      "North Carolina (ACC).csv\n",
      "Gonzaga (WCC).csv\n",
      "California (Pac-12).csv\n",
      "UT Martin (OVC).csv\n",
      "VCU (Atlantic 10).csv\n",
      "Texas A&M (SEC).csv\n",
      "UC Irvine (Big West).csv\n",
      "South Carolina St. (MEAC).csv\n",
      "UMKC (WAC).csv\n",
      "A&M-Corpus Christi (Southland).csv\n",
      "Hawaii (Big West).csv\n",
      "Appalachian St. (Sun Belt).csv\n",
      "Western Ill. (Summit League).csv\n",
      "UNI (MVC).csv\n",
      "Penn St. (Big Ten).csv\n",
      "Hofstra (CAA).csv\n",
      "Seattle U (WAC).csv\n",
      "Stanford (Pac-12).csv\n",
      "UCLA (Pac-12).csv\n",
      "South Dakota St. (Summit League).csv\n",
      "Pittsburgh (ACC).csv\n",
      "Ole Miss (SEC).csv\n",
      "Texas St. (Sun Belt).csv\n",
      "Cal Poly (Big West).csv\n",
      "Grambling (SWAC).csv\n",
      "Central Ark. (Southland).csv\n",
      "Morgan St. (MEAC).csv\n",
      "Prairie View (SWAC).csv\n",
      "Evansville (MVC).csv\n",
      "Campbell (Big South).csv\n",
      "Georgia Tech (ACC).csv\n",
      "UIC (Horizon).csv\n",
      "Oregon St. (Pac-12).csv\n",
      "Portland St. (Big Sky).csv\n",
      "Alabama (SEC).csv\n",
      "Lamar University (Southland).csv\n",
      "SMU (AAC).csv\n",
      "Alabama A&M (SWAC).csv\n",
      "San Diego (WCC).csv\n",
      "CSU Bakersfield (WAC).csv\n",
      "Baylor (Big 12).csv\n",
      "Southeastern La. (Southland).csv\n",
      "Marist (MAAC).csv\n",
      "Montana St. (Big Sky).csv\n",
      "Bucknell (Patriot).csv\n",
      "UNC Greensboro (SoCon).csv\n",
      "Auburn (SEC).csv\n",
      "Murray St. (OVC).csv\n",
      "Fairfield (MAAC).csv\n",
      "Morehead St. (OVC).csv\n",
      "Minnesota (Big Ten).csv\n",
      "Temple (AAC).csv\n",
      "Ball St. (MAC).csv\n",
      "The Citadel (SoCon).csv\n",
      "Akron (MAC).csv\n",
      "Southern U. (SWAC).csv\n",
      "Utah (Pac-12).csv\n",
      "Rhode Island (Atlantic 10).csv\n",
      "Troy (Sun Belt).csv\n",
      "Furman (SoCon).csv\n",
      "Towson (CAA).csv\n",
      "Eastern Ky. (OVC).csv\n",
      "Milwaukee (Horizon).csv\n",
      "Wichita St. (AAC).csv\n",
      "Niagara (MAAC).csv\n",
      "Cal St. Fullerton (Big West).csv\n",
      "Ohio St. (Big Ten).csv\n",
      "UC Santa Barbara (Big West).csv\n",
      "Toledo (MAC).csv\n",
      "Rutgers (Big Ten).csv\n",
      "San Francisco (WCC).csv\n",
      "Colorado (Pac-12).csv\n",
      "Clemson (ACC).csv\n",
      "ETSU (SoCon).csv\n",
      "Lehigh (Patriot).csv\n",
      "High Point (Big South).csv\n",
      "Maryland (Big Ten).csv\n",
      "Utah Valley (WAC).csv\n",
      "Youngstown St. (Horizon).csv\n",
      "Rider (MAAC).csv\n",
      "Missouri St. (MVC).csv\n",
      "Radford (Big South).csv\n",
      "Gardner-Webb (Big South).csv\n",
      "Marshall (C-USA).csv\n",
      "Hampton (Big South).csv\n",
      "Jacksonville (ASUN).csv\n",
      "Idaho St. (Big Sky).csv\n",
      "Loyola Marymount (WCC).csv\n",
      "Central Mich. (MAC).csv\n",
      "Austin Peay (OVC).csv\n",
      "Northwestern St. (Southland).csv\n",
      "North Florida (ASUN).csv\n",
      "Savannah St. (MEAC).csv\n",
      "New Orleans (Southland).csv\n",
      "McNeese (Southland).csv\n",
      "Fordham (Atlantic 10).csv\n",
      "Butler (Big East).csv\n",
      "Chicago St. (WAC).csv\n",
      "BYU (WCC).csv\n",
      "Howard (MEAC).csv\n",
      "Virginia Tech (ACC).csv\n",
      "Nicholls St. (Southland).csv\n",
      "IUPUI (Horizon).csv\n",
      "Notre Dame (ACC).csv\n",
      "Harvard (Ivy League).csv\n",
      "UMass Lowell (America East).csv\n",
      "N.C. Central (MEAC).csv\n",
      "South Dakota (Summit League).csv\n",
      "George Washington (Atlantic 10).csv\n",
      "Florida A&M (MEAC).csv\n",
      "Duke (ACC).csv\n",
      "Indiana (Big Ten).csv\n",
      "FIU (C-USA).csv\n",
      "Robert Morris (NEC).csv\n",
      "Louisiana (Sun Belt).csv\n",
      "Iona (MAAC).csv\n",
      "Stetson (ASUN).csv\n",
      "West Virginia (Big 12).csv\n",
      "UT Arlington (Sun Belt).csv\n",
      "Kansas St. (Big 12).csv\n",
      "Georgia St. (Sun Belt).csv\n",
      "Hartford (America East).csv\n",
      "Denver (Summit League).csv\n",
      "Wofford (SoCon).csv\n",
      "Georgetown (Big East).csv\n",
      "Ohio (MAC).csv\n",
      "Oral Roberts (Summit League).csv\n",
      "Dayton (Atlantic 10).csv\n",
      "Tennessee (SEC).csv\n",
      "Illinois St. (MVC).csv\n",
      "North Dakota St. (Summit League).csv\n",
      "Southern Ill. (MVC).csv\n",
      "Bowling Green (MAC).csv\n",
      "Buffalo (MAC).csv\n",
      "Davidson (Atlantic 10).csv\n",
      "Chattanooga (SoCon).csv\n",
      "Xavier (Big East).csv\n",
      "Col. of Charleston (CAA).csv\n",
      "La Salle (Atlantic 10).csv\n",
      "Drake (MVC).csv\n",
      "Nebraska (Big Ten).csv\n",
      "Army West Point (Patriot).csv\n",
      "Holy Cross (Patriot).csv\n",
      "UTEP (C-USA).csv\n",
      "Loyola Maryland (Patriot).csv\n",
      "Grand Canyon (WAC).csv\n",
      "Pacific (WCC).csv\n",
      "Eastern Mich. (MAC).csv\n",
      "San Jose St. (MWC).csv\n",
      "Columbia (Ivy League).csv\n",
      "Elon (CAA).csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "year = 2018\n",
    "for root, dirs, files in os.walk(f'../../data/ncaa/raw/{year}/team_game_by_game/'):\n",
    "    for i in tnrange(len(files), desc='Cleaning data'):\n",
    "        print(files[i])\n",
    "        f = files[i]\n",
    "        df = pd.read_csv(Path(root).joinpath(f), header=1)\n",
    "        if year >= 2018:\n",
    "            df.drop(columns=[\"MP\", \"Attend\", \"BHE\", \"Unnamed: 20\"], inplace=True)\n",
    "        else:\n",
    "            df.drop(labels=[\"MP\", \"BHE\", \"Unnamed: 19\"], axis=1, inplace=True)\n",
    "        df.replace({'/':''}, regex=True, inplace=True)\n",
    "        df.fillna(0, inplace=True)\n",
    "        df[[\"Kills\", \"Errors\", \"Total Attacks\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\"]] = df[[\"Kills\", \"Errors\", \"Total Attacks\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\"]].astype(int)\n",
    "        outpath = Path(root).parent.parent.parent.joinpath(f\"processed/{year}/game_by_game_cleaned/\")\n",
    "        outpath.mkdir(parents=True, exist_ok=True)\n",
    "        f = f[:f.find('(') - 1] + \".csv\"\n",
    "        df.to_csv(outpath.joinpath(f), index=False)"
   ]
  },
  {
   "source": [
    "# Computing Moving Averages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_team_data(input_dir, output_dir, tf):\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        new_root = Path(output_dir)\n",
    "        new_root.mkdir(parents=True, exist_ok=True)\n",
    "        for f in files:\n",
    "            df = pd.read_csv(Path(root).joinpath(f))\n",
    "            tf(df)\n",
    "            df.to_csv(new_root.joinpath(f), index=False)\n",
    "\n",
    "features = [\"Kills\", \"Errors\", \"Total Attacks\", \"Hit Pct\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\", \"PTS\"]"
   ]
  },
  {
   "source": [
    "## Simple Moving Average"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 10\n",
    "year = 2016\n",
    "\n",
    "def sma(df):\n",
    "    df[features] = df[features].rolling(window, min_periods=1).mean()\n",
    "\n",
    "transform_team_data(\n",
    "    input_dir=f'../../data/ncaa/processed/{year}/game_by_game_cleaned',\n",
    "    output_dir=f'../../data/ncaa/processed/{year}/game_by_game_{window}_sma',\n",
    "    tf=sma,\n",
    ")"
   ]
  },
  {
   "source": [
    "## Cumulative Moving Average"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2016\n",
    "\n",
    "def cma(df):\n",
    "    df[features] = df[features].expanding().mean()\n",
    "\n",
    "transform_team_data(\n",
    "    input_dir=f'../../data/ncaa/processed/{year}/game_by_game_cleaned',\n",
    "    output_dir=f'../../data/ncaa/processed/{year}/game_by_game_cma',\n",
    "    tf=cma,\n",
    ")"
   ]
  },
  {
   "source": [
    "## Exponential Moving Average"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2016\n",
    "alpha = 0.2\n",
    "\n",
    "def ewm(df):\n",
    "    df[features] = df[features].ewm(alpha=alpha).mean()\n",
    "\n",
    "transform_team_data(\n",
    "    input_dir=f'../../data/ncaa/processed/{year}/game_by_game_cleaned',\n",
    "    output_dir=f'../../data/ncaa/processed/{year}/game_by_game_{alpha}_ewm',\n",
    "    tf=ewm,\n",
    ")"
   ]
  },
  {
   "source": [
    "# Combine into single dataframe of matches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Utility Function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    name = name.replace('\\\"', '')\n",
    "    if '@' in name:\n",
    "        if name.index('@') == 0:\n",
    "            return name[2:]\n",
    "        else:\n",
    "            return name[:name.index('@')-1]\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "features = [\"Kills\", \"Errors\", \"Total Attacks\", \"Hit Pct\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\", \"PTS\"]\n",
    "combined_features = [\"Date\", \"TeamA\", \"TeamB\", \"Result\", \"S\", \"Team A Kills\", \"Team A Errors\", \"Team A Total Attacks\", \"Team A Hit Pct\", \"Team A Assists\", \"Team A Aces\", \"Team A SErr\", \"Team A Digs\", \"Team A RErr\", \"Team A Block Solos\", \"Team A Block Assists\", \"Team A BErr\", \"Team A PTS\", \"Team B Kills\", \"Team B Errors\", \"Team B Total Attacks\", \"Team B Hit Pct\", \"Team B Assists\", \"Team B Aces\", \"Team B SErr\", \"Team B Digs\", \"Team B RErr\", \"Team B Block Solos\", \"Team B Block Assists\", \"Team B BErr\", \"Team B PTS\"]\n",
    "\n",
    "\n",
    "def combine(input_path, output_path):\n",
    "    dfs = []\n",
    "    team_names = []\n",
    "    for root, dirs, files in os.walk(input_path):\n",
    "        for f in files:\n",
    "            team_names.append(f[:-4])\n",
    "            dfs.append(pd.read_csv(Path(root).joinpath(f)))\n",
    "\n",
    "    data = []\n",
    "\n",
    "    err_a = 0\n",
    "    err_b = 0\n",
    "\n",
    "    for i, name in enumerate(team_names):\n",
    "        df = dfs[i]\n",
    "        for j, TeamA_row in df.iterrows(): \n",
    "            date = TeamA_row[\"Date\"]\n",
    "            TeamA = name\n",
    "            TeamB = clean_name(TeamA_row[\"Opponent\"])\n",
    "            Result = 1 if TeamA_row[\"Result\"][0] == 'W' else 0\n",
    "            S = TeamA_row[\"S\"]\n",
    "            TeamA_stats = TeamA_row[features]\n",
    "            try:\n",
    "                TeamB_df = dfs[team_names.index(TeamB)]\n",
    "            except:\n",
    "                err_a += 1\n",
    "                continue\n",
    "            try:\n",
    "                TeamB_row = TeamB_df[TeamB_df[\"Date\"] == date][TeamB_df[\"Opponent\"].str.contains(TeamA)].reset_index().loc[0]\n",
    "            except:\n",
    "                err_b += 1\n",
    "                continue\n",
    "\n",
    "            TeamB_stats = TeamB_row[features]\n",
    "            data.append([date, TeamA, TeamB, Result, S, *TeamA_stats, *TeamB_stats])\n",
    "        \n",
    "    combined_df = pd.DataFrame(data, columns=combined_features)\n",
    "    combined_df.to_csv(output_path, index=False)\n",
    "    return dict(df_length=len(combined_df), err_a=err_a, err_b=err_b)\n",
    "\n",
    "def prev_combine(input_path, output_path):\n",
    "    dfs = []\n",
    "    team_names = []\n",
    "    for root, dirs, files in os.walk(input_path):\n",
    "        for f in files:\n",
    "            team_names.append(f[:-4])\n",
    "            dfs.append(pd.read_csv(Path(root).joinpath(f)))\n",
    "\n",
    "    data = []\n",
    "\n",
    "    err_a = 0\n",
    "    err_b = 0\n",
    "\n",
    "    for i, name in enumerate(team_names):\n",
    "        df = dfs[i]\n",
    "        for j in range(len(df)):\n",
    "            if j == 0:\n",
    "                continue\n",
    "            TeamA_row = df.loc[j-1]\n",
    "            date = TeamA_row[\"Date\"]\n",
    "            TeamA = name\n",
    "            TeamB = clean_name(TeamA_row[\"Opponent\"])\n",
    "            Result = 1 if TeamA_row[\"Result\"][0] == 'W' else 0\n",
    "            S = TeamA_row[\"S\"]\n",
    "            TeamA_stats = TeamA_row[features]\n",
    "            try:\n",
    "                TeamB_df = dfs[team_names.index(TeamB)]\n",
    "            except:\n",
    "                err_a += 1\n",
    "                continue\n",
    "            try:\n",
    "                TeamB_row_index = TeamB_df[TeamB_df[\"Date\"] == date][TeamB_df[\"Opponent\"].str.contains(TeamA)].index[0]\n",
    "                if TeamB_row_index == 0:\n",
    "                    continue\n",
    "                TeamB_row = TeamB_df.loc[TeamB_row_index-1]\n",
    "            except:\n",
    "                err_b += 1\n",
    "                continue\n",
    "\n",
    "            TeamB_stats = TeamB_row[features]\n",
    "            data.append([date, TeamA, TeamB, Result, S, *TeamA_stats, *TeamB_stats])\n",
    "        \n",
    "    combined_df = pd.DataFrame(data, columns=combined_features)\n",
    "    combined_df.to_csv(output_path, index=False)\n",
    "    return dict(df_length=len(combined_df), err_a=err_a, err_b=err_b)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Combine dataframe of math by match result without any averages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'df_length': 9487, 'err_a': 440, 'err_b': 60}"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "combine(\n",
    "    input_path=f'../../data/ncaa/processed/{year}/game_by_game_cleaned',\n",
    "    output_path=f'../../data/ncaa/processed/{year}/accumulated/matches_gathered.csv',\n",
    ")\n"
   ]
  },
  {
   "source": [
    "## Combine dataframe for Simple Moving Average"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'df_length': 8852, 'err_a': 430, 'err_b': 58}"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "year = 2016\n",
    "window = 10\n",
    "prev_combine(\n",
    "    input_path=f'../../data/ncaa/processed/{year}/game_by_game_{window}_sma',\n",
    "    output_path=f'../../data/ncaa/processed/{year}/accumulated/{window}_sma.csv',\n",
    ")"
   ]
  },
  {
   "source": [
    "## Combine dataframe for Cumulative Moving Average"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'df_length': 8852, 'err_a': 430, 'err_b': 58}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "year = 2016\n",
    "window = 10\n",
    "prev_combine(\n",
    "    input_path=f'../../data/ncaa/processed/{year}/game_by_game_cma',\n",
    "    output_path=f'../../data/ncaa/processed/{year}/accumulated/cma.csv',\n",
    ")"
   ]
  },
  {
   "source": [
    "## Combine dataframe for Exponentially Moving Average"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'df_length': 8852, 'err_a': 430, 'err_b': 58}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "year = 2016\n",
    "alpha = 0.2\n",
    "prev_combine(\n",
    "    input_path=f'../../data/ncaa/processed/{year}/game_by_game_{alpha}_ewm',\n",
    "    output_path=f'../../data/ncaa/processed/{year}/accumulated/{alpha}_ewm.csv',\n",
    ")"
   ]
  },
  {
   "source": [
    "# Clean Player Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fetching for Lockin, Hannah ... "
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/twm/comp/ml/volleyball-ml/data/ncaa/raw/2019/player_game_wise/Baylor (Big 12)/Lockin, Hannah.csv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4a13fa928d49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mstore_player\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-4a13fa928d49>\u001b[0m in \u001b[0;36mstore_player\u001b[0;34m(url, path)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Fetching for {Path(path).name[:-4]} ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.101 Safari/537.36\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3-envs/AI/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[1;32m   3165\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3166\u001b[0m         )\n\u001b[0;32m-> 3167\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3-envs/AI/lib/python3.6/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             )\n\u001b[1;32m    192\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3-envs/AI/lib/python3.6/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/twm/comp/ml/volleyball-ml/data/ncaa/raw/2019/player_game_wise/Baylor (Big 12)/Lockin, Hannah.csv'"
     ]
    }
   ],
   "source": [
    "def store_player(url, path):\n",
    "    print(f\"Fetching for {Path(path).name[:-4]} ...\", end=' ')\n",
    "    r = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2272.101 Safari/537.36\"})\n",
    "    pd.read_html(r.text)[-1].drop(labels=[0], axis=0).to_csv(path, index=False)\n",
    "    print(\"Done!\")\n",
    "\n",
    "urls = [\n",
    "    \"https://stats.ncaa.org/player/index?game_sport_year_ctl_id=14942&org_id=51&stats_player_seq=1906568\",\n",
    "    \"https://stats.ncaa.org/player/index?game_sport_year_ctl_id=14942&org_id=77&stats_player_seq=2020914\",\n",
    "    \"https://stats.ncaa.org/player/index?game_sport_year_ctl_id=14942&org_id=136&stats_player_seq=2259847\",\n",
    "    \"https://stats.ncaa.org/player/index?game_sport_year_ctl_id=14942&org_id=196&stats_player_seq=2199752\",\n",
    "    \"https://stats.ncaa.org/player/index?game_sport_year_ctl_id=14942&org_id=255&stats_player_seq=2206497\",\n",
    "    \"https://stats.ncaa.org/player/index?game_sport_year_ctl_id=14942&org_id=648&stats_player_seq=2199107\",\n",
    "    \"https://stats.ncaa.org/player/index?game_sport_year_ctl_id=14942&org_id=141&stats_player_seq=1920987\",\n",
    "    \"https://stats.ncaa.org/player/index?game_sport_year_ctl_id=14942&org_id=731&stats_player_seq=1787509\",\n",
    "    \"https://stats.ncaa.org/player/index?game_sport_year_ctl_id=14942&org_id=782&stats_player_seq=2210530\",\n",
    "    \"https://stats.ncaa.org/player/index?game_sport_year_ctl_id=14942&org_id=731&stats_player_seq=2020474\",\n",
    "]\n",
    "paths = [\n",
    "    \"/home/veds12/Desktop/Projects/volleyball-ml/data/ncaa/raw/2019/player_game_wise/Baylor (Big 12)/Lockin, Hannah.csv\",\n",
    "    \"/home/veds12/Desktop/Projects/volleyball-ml/data/ncaa/raw/2019/player_game_wise/BYU (WCC)/Tausinga, Tayler.csv\",\n",
    "    \"/home/veds12/Desktop/Projects/volleyball-ml/data/ncaa/raw/2019/player_game_wise/Chicago St. (WAC)/Sisic, Isadora.csv\",\n",
    "    \"/home/veds12/Desktop/Projects/volleyball-ml/data/ncaa/raw/2019/player_game_wise/East Carolina (AAC)/Garcia, Jaylibeth.csv\",\n",
    "    \"/home/veds12/Desktop/Projects/volleyball-ml/data/ncaa/raw/2019/player_game_wise/Georgia Tech (ACC)/Lamborda, Paola.csv\",\n",
    "    \"/home/veds12/Desktop/Projects/volleyball-ml/data/ncaa/raw/2019/player_game_wise/South Carolina (SEC)/Covas Córdova, Camilla.csv\",\n",
    "    \"/home/veds12/Desktop/Projects/volleyball-ml/data/ncaa/raw/2019/player_game_wise/The Citadel (SoCon)/Jesus, Sharlissa.csv\",\n",
    "    \"/home/veds12/Desktop/Projects/volleyball-ml/data/ncaa/raw/2019/player_game_wise/Utah St. (Mountain West)/Olson-Shepherd, Madi.csv\",\n",
    "    \"/home/veds12/Desktop/Projects/volleyball-ml/data/ncaa/raw/2019/player_game_wise/Wichita St. (AAC)/Uluave, Sina.csv\",\n",
    "    \"/home/veds12/Desktop/Projects/volleyball-ml/data/ncaa/raw/2019/player_game_wise/Utah St. (Mountain West)/Solosabal, Whitney.csv\",\n",
    "]\n",
    "\n",
    "for url, path in zip(urls, paths):\n",
    "    store_player(url, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2018\n",
    "verbose = False\n",
    "\n",
    "for root, dirs, _ in os.walk(f'../../data/ncaa/raw/{year}/player_game_wise/'):\n",
    "    for team_dir in dirs:\n",
    "        team_root, _, player_files = list(os.walk(Path(root).joinpath(team_dir)))[0]\n",
    "        team_name = Path(team_root).name\n",
    "        team_name = team_name[:team_name.find('(') - 1]\n",
    "        if verbose:\n",
    "            print(f\"Cleaning player data for {team_name} ...\")\n",
    "        for player_file in player_files:\n",
    "            if verbose:\n",
    "                print(f\"\\tCleaning data for player {player_file[:-4]} ...\", end=' ')\n",
    "            outpath = Path(root).parent.parent.parent.joinpath(f\"processed/{year}/player_game_wise_cleaned/{team_name}\")\n",
    "            if outpath.joinpath(player_file).is_file():\n",
    "                if verbose:\n",
    "                    print(\"Already Exists!\")\n",
    "                continue\n",
    "            try:\n",
    "                df = pd.read_csv(Path(team_root).joinpath(player_file), header=1)\n",
    "            except:\n",
    "                print(f\"{Path(team_root).joinpath(player_file)} Failed!\")\n",
    "                continue\n",
    "            \n",
    "            df.drop(columns=[\"MP\", \"Attend\", \"BHE\", \"Unnamed: 20\"], inplace=True)\n",
    "            df.replace({'/':''}, regex=True, inplace=True)\n",
    "            df.fillna(0, inplace=True)\n",
    "            df[[\"Kills\", \"Errors\", \"Total Attacks\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\"]] = df[[\"Kills\", \"Errors\", \"Total Attacks\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\"]].astype(int)\n",
    "            outpath.mkdir(parents=True, exist_ok=True)\n",
    "            df.to_csv(outpath.joinpath(player_file), index=False)\n",
    "            if verbose:\n",
    "                print(\"Done!\")\n",
    "\n",
    "for root, dirs, _ in os.walk('/home/veds12/Desktop/Projects/volleyball-ml/data/ncaa/processed/2019/player_game_wise_cleaned'):\n",
    "    for team_dir in dirs:\n",
    "        for team_root, _, player_files in os.walk(Path(root).joinpath(team_dir)):\n",
    "            for player_file in player_files:\n",
    "                if player_file[player_file.find(\".csv\") - 1] == ' ':\n",
    "                    cp = Path(team_root).joinpath(player_file)\n",
    "                    n = player_file[:player_file.find(\".csv\") - 1] + \".csv\"\n",
    "                    print(cp.rename(cp.parent.joinpath(n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_player_data(input_dir, output_dir, tf):\n",
    "    for root, dirs, _ in os.walk(input_dir):\n",
    "        for team_dir in dirs:\n",
    "            for team_root, _, player_files in os.walk(Path(root).joinpath(team_dir)):\n",
    "                for player_file in player_files:\n",
    "                    df = pd.read_csv(Path(team_root).joinpath(player_file))\n",
    "                    outpath = Path(output_dir).joinpath(team_dir)\n",
    "                    tf(df)\n",
    "                    outpath.mkdir(parents=True, exist_ok=True)\n",
    "                    df.to_csv(outpath.joinpath(player_file), index=False)\n",
    "\n",
    "features = [\"Kills\", \"Errors\", \"Total Attacks\", \"Hit Pct\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\", \"PTS\"]"
   ]
  },
  {
   "source": [
    "## SMA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'transform_player_data' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9ccb9306982a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m transform_player_data(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0minput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'../../data/ncaa/processed/{year}/player_game_wise_cleaned/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'../../data/ncaa/processed/{year}/player_game_wise_{window}_sma/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transform_player_data' is not defined"
     ]
    }
   ],
   "source": [
    "year = 2018\n",
    "window = 10\n",
    "\n",
    "def sma(df):\n",
    "    df[features] = df[features].rolling(window, min_periods=1).mean()\n",
    "\n",
    "\n",
    "transform_player_data(\n",
    "    input_dir=f'../../data/ncaa/processed/{year}/player_game_wise_cleaned/',\n",
    "    output_dir=f'../../data/ncaa/processed/{year}/player_game_wise_{window}_sma/',\n",
    "    tf=sma\n",
    ")"
   ]
  },
  {
   "source": [
    "## CMA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2018\n",
    "\n",
    "def cma(df):\n",
    "    df[features] = df[features].expanding().mean()\n",
    "\n",
    "transform_player_data(\n",
    "    input_dir=f'../../data/ncaa/processed/{year}/player_game_wise_cleaned/',\n",
    "    output_dir=f'../../data/ncaa/processed/{year}/player_game_wise_cma/',\n",
    "    tf=cma\n",
    ")"
   ]
  },
  {
   "source": [
    "## EWM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2018\n",
    "alpha = 0.2\n",
    "\n",
    "def ewm(df):\n",
    "    df[features] = df[features].ewm(alpha=alpha).mean()\n",
    "\n",
    "transform_player_data(\n",
    "    input_dir=f'../../data/ncaa/processed/{year}/player_game_wise_cleaned/',\n",
    "    output_dir=f'../../data/ncaa/processed/{year}/player_game_wise_{alpha}_ewm/',\n",
    "    tf=ewm\n",
    ")"
   ]
  },
  {
   "source": [
    "# Combining into single dataframe"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    if '@' in name:\n",
    "        if name.index('@') == 0:\n",
    "            return name[2:]\n",
    "        else:\n",
    "            return name[:name.index('@')-1]\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "features = [\"Kills\", \"Errors\", \"Total Attacks\", \"Hit Pct\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\", \"PTS\"]\n",
    "player_features = [f\"Player {j} {f}\" for f in features for j in range(12)]\n",
    "combined_features = [\n",
    "\"Date\", \"TeamA\", \"TeamB\", \"Result\", \"S\", \"Team A Kills\", \"Team A Errors\", \"Team A Total Attacks\", \"Team A Hit Pct\", \"Team A Assists\", \"Team A Aces\", \"Team A SErr\", \"Team A Digs\",  \"Team A RErr\", \"Team A Block Solos\", \"Team A Block Assists\", \"Team A BErr\", \"Team A PTS\", \"Team B Kills\", \"Team B Errors\", \"Team B Total Attacks\", \"Team B Hit Pct\", \"Team B Assists\", \"Team B Aces\", \"Team B SErr\", \"Team B Digs\", \"Team B RErr\", \"Team B Block Solos\", \"Team B Block Assists\", \"Team B BErr\", \"Team B PTS\",\n",
    "*[f\"Team A {s}\" for s in player_features],\n",
    "*[f\"Team B {s}\" for s in player_features]\n",
    "]\n",
    "\n",
    "\n",
    "def combine_with_player(player_input_path, team_stats_path, team_matches_path, macthes_with_player_info_path, combined_output_path):\n",
    "    print(\"Combining player data for individual teams ...\")\n",
    "\n",
    "    print(\"Building team index ...\", end=' ')\n",
    "    team_names = []\n",
    "    for root, _, files in os.walk(team_matches_path):\n",
    "        for f in files:\n",
    "            team_names.append(f[:-4])\n",
    "\n",
    "    print(\"Done!\")\n",
    "\n",
    "    player_input_path = Path(player_input_path)\n",
    "    team_stats_path = Path(team_stats_path)\n",
    "    team_matches_path = Path(team_matches_path)\n",
    "    macthes_with_player_info_path = Path(macthes_with_player_info_path)\n",
    "    macthes_with_player_info_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "\n",
    "    print(\"Sorting team data ...\", end=' ')\n",
    "    for i, name in enumerate(team_names):\n",
    "        team_matches_df = pd.read_csv(team_matches_path.joinpath(f\"{name}.csv\"))\n",
    "        team_stats_df = pd.read_csv(team_stats_path.joinpath(f\"{name}.csv\"))\n",
    "        top_player_names = [] \n",
    "        for j, (_, player_row) in enumerate(team_stats_df[team_stats_df.Player != \"TEAM\"][team_stats_df.Player != \"Totals\"][team_stats_df.Player != \"Opponent Totals\"].sort_values(by=[\"GP\"], ascending=False).iterrows()):\n",
    "            top_player_names.append(player_row[\"Player\"])\n",
    "            if j == 11:\n",
    "                break\n",
    "        try:\n",
    "            for j, player in enumerate(top_player_names):\n",
    "                team_matches_df[[f\"Player {j} {f}\" for f in features]] = pd.read_csv(player_input_path.joinpath(f\"{name}/{player}.csv\"))[features]\n",
    "            team_matches_df.to_csv(macthes_with_player_info_path.joinpath(f\"{name}.csv\"), index=False)        \n",
    "        except:\n",
    "            print(f\"\\nFailed to get player {player} for {name}!\")\n",
    "            continue\n",
    "    print(\"Done!\")\n",
    "\n",
    "    print(\"Getting match wise dataframes ...\", end=' ')\n",
    "    dfs = []\n",
    "    for root, _, files in os.walk(macthes_with_player_info_path):\n",
    "        for f in files:\n",
    "            dfs.append(pd.read_csv(Path(root).joinpath(f)))\n",
    "    print(\"Done!\")\n",
    "\n",
    "    err_a, err_b = 0, 0\n",
    "    data = []\n",
    "    for i in tnrange(len(dfs), desc=\"Combining into single df\"):\n",
    "        name = team_names[i]\n",
    "        df = dfs[i]\n",
    "        for j in range(len(df)):\n",
    "            if j == 0:\n",
    "                continue\n",
    "            TeamA_row = df.loc[j-1]\n",
    "            date = TeamA_row[\"Date\"]\n",
    "            TeamA = name\n",
    "            TeamB = clean_name(TeamA_row[\"Opponent\"])\n",
    "            Result = 1 if TeamA_row[\"Result\"][0] == 'W' else 0\n",
    "            S = TeamA_row[\"S\"]\n",
    "            TeamA_stats = TeamA_row[features + player_features]\n",
    "            try:\n",
    "                TeamB_df = dfs[team_names.index(TeamB)]\n",
    "            except:\n",
    "                err_a += 1\n",
    "                continue\n",
    "            try:\n",
    "                TeamB_row_index = TeamB_df[TeamB_df[\"Date\"] == date][TeamB_df[\"Opponent\"].str.contains(TeamA)].index[0]\n",
    "                if TeamB_row_index == 0:\n",
    "                    continue\n",
    "                TeamB_row = TeamB_df.loc[TeamB_row_index-1]\n",
    "            except:\n",
    "                err_b += 1\n",
    "                continue\n",
    "\n",
    "            TeamB_stats = TeamB_row[features + player_features]\n",
    "            data.append([date, TeamA, TeamB, Result, S, *TeamA_stats, *TeamB_stats])\n",
    "\n",
    "    combined_df = pd.DataFrame(data, columns=combined_features)\n",
    "    combined_df.to_csv(combined_output_path, index=False)\n",
    "    return dict(df_len=len(combined_df), err_a=err_a, err_b=err_b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Combining player data for individual teams ...\n",
      "Building team index ... Done!\n",
      "Sorting team data ... \n",
      "Failed to get player Krenik, Paige for USC Upstate!\n",
      "\n",
      "Failed to get player Gasser, Haylee for Clemson!\n",
      "\n",
      "Failed to get player Cerame, Paula for North Dakota!\n",
      "\n",
      "Failed to get player Nwosu, Udo for Army West Point!\n",
      "\n",
      "Failed to get player Solis, Emily for SIUE!\n",
      "\n",
      "Failed to get player Whalen, Mariah for Indiana!\n",
      "\n",
      "Failed to get player Shelley, Kennedy for Arkansas St.!\n",
      "\n",
      "Failed to get player Sass, Olivia for Arizona!\n",
      "\n",
      "Failed to get player Sweder, Thea for Little Rock!\n",
      "\n",
      "Failed to get player Schaffer, Albany for Campbell!\n",
      "\n",
      "Failed to get player Patriciello, Sabrina for UTSA!\n",
      "\n",
      "Failed to get player Jake-Turner, Kennadie for Rhode Island!\n",
      "\n",
      "Failed to get player Lewis, Mary Hannah for Saint Louis!\n",
      "\n",
      "Failed to get player Gunter, Sydney for Cincinnati!\n",
      "\n",
      "Failed to get player Gates, Madison for Lehigh!\n",
      "\n",
      "Failed to get player Ehlert, Makena for Winthrop!\n",
      "\n",
      "Failed to get player Rodriguez, Nicole for Nicholls St.!\n",
      "\n",
      "Failed to get player Berg, Taylor for William & Mary!\n",
      "\n",
      "Failed to get player Hinz, Danielle for McNeese!\n",
      "\n",
      "Failed to get player Schoen, Halle for N.C. A&T!\n",
      "\n",
      "Failed to get player Cerasoli, Gabbi for Duquesne!\n",
      "\n",
      "Failed to get player Kline, Maddy for Wisconsin!\n",
      "\n",
      "Failed to get player Osuegbu, Toya for Temple!\n",
      "\n",
      "Failed to get player Johnson, Damadj for Coastal Caro.!\n",
      "\n",
      "Failed to get player LaGoy, Lexi for Eastern Mich.!\n",
      "\n",
      "Failed to get player Vukoja, Dubravka for Incarnate Word!\n",
      "\n",
      "Failed to get player Pitt, Courteney for Penn St.!\n",
      "\n",
      "Failed to get player Johnson, Sarah for Iowa St.!\n",
      "\n",
      "Failed to get player Wolf, Jessica for Central Conn. St.!\n",
      "\n",
      "Failed to get player Miller, Morgan for Tennessee!\n",
      "\n",
      "Failed to get player Babic, Lucia for Robert Morris!\n",
      "\n",
      "Failed to get player Dragovic, Nada for N.C. Central!\n",
      "\n",
      "Failed to get player Sullivan, Erika for FGCU!\n",
      "\n",
      "Failed to get player Light, Liliana for Jacksonville St.!\n",
      "\n",
      "Failed to get player Brown, Donna for SMU!\n",
      "\n",
      "Failed to get player Ng, Angelee for Murray St.!\n",
      "\n",
      "Failed to get player Wilson, Claudia for Butler!\n",
      "\n",
      "Failed to get player Adams, Nicole for Western Ill.!\n",
      "\n",
      "Failed to get player Barber, Lily for UC Davis!\n",
      "\n",
      "Failed to get player Murawinski, Julia for Seattle U!\n",
      "\n",
      "Failed to get player Smith, Kirby for Montana!\n",
      "\n",
      "Failed to get player McDermott, Erin for Oral Roberts!\n",
      "\n",
      "Failed to get player Dowell, Mckenzie for Syracuse!\n",
      "\n",
      "Failed to get player Strawberry, Jewel for Valparaiso!\n",
      "\n",
      "Failed to get player Terwilliger, Emma for Col. of Charleston!\n",
      "\n",
      "Failed to get player Akason, Taylor for Michigan!\n",
      "\n",
      "Failed to get player Stokes, Milan for SFA!\n",
      "\n",
      "Failed to get player Stander, Mia for Mercer!\n",
      "\n",
      "Failed to get player Rivera, Natalia for Missouri St.!\n",
      "\n",
      "Failed to get player Andrews, Keeghan for Northwestern!\n",
      "\n",
      "Failed to get player Wojick, Sarah for Florida St.!\n",
      "\n",
      "Failed to get player Pleasants, Jordan for Ole Miss!\n",
      "\n",
      "Failed to get player Squier, Faith for LSU!\n",
      "\n",
      "Failed to get player Peonia, Dora for UMBC!\n",
      "\n",
      "Failed to get player Humphrey, Jade for Hofstra!\n",
      "\n",
      "Failed to get player Martin, Madison for Hawaii!\n",
      "\n",
      "Failed to get player Marshall, Savannah for Virginia!\n",
      "\n",
      "Failed to get player Price, Hannah for Alabama A&M!\n",
      "\n",
      "Failed to get player Galloway, Cambria for Kansas St.!\n",
      "\n",
      "Failed to get player Gill, Sumeet for Milwaukee!\n",
      "\n",
      "Failed to get player Lewis, Ashley for Northeastern!\n",
      "\n",
      "Failed to get player Bolozan, Bojana for The Citadel!\n",
      "\n",
      "Failed to get player Coale, Olivia for Kentucky!\n",
      "\n",
      "Failed to get player Krivdo, Kaitlan for UMass Lowell!\n",
      "\n",
      "Failed to get player Holtzclaw, Kiera for Boise St.!\n",
      "\n",
      "Failed to get player Schaible, Lindsey for Marquette!\n",
      "\n",
      "Failed to get player Swayze, Sam for NC State!\n",
      "\n",
      "Failed to get player Langridge, Jessica for Bradley!\n",
      "\n",
      "Failed to get player Macken, Charlotte for Abilene Christian!\n",
      "\n",
      "Failed to get player Paumen, Brynn for Bowling Green!\n",
      "\n",
      "Failed to get player Tiedt, Nina for California!\n",
      "\n",
      "Failed to get player Clark, Katie for UNLV!\n",
      "\n",
      "Failed to get player Langford, Kamille for Utah Valley!\n",
      "\n",
      "Failed to get player Marshall, Maddy for Wichita St.!\n",
      "\n",
      "Failed to get player Hartman, Lauren for New Orleans!\n",
      "\n",
      "Failed to get player Bebout, Taylor for Saint Mary's!\n",
      "\n",
      "Failed to get player Hoffman, Haley for Washington!\n",
      "\n",
      "Failed to get player Kathariou, Ariadni for Houston!\n",
      "\n",
      "Failed to get player Crocker, Cori for Montana St.!\n",
      "\n",
      "Failed to get player Reid, Abbi for West Virginia!\n",
      "\n",
      "Failed to get player Karsseboom, Brianna for LIU Brooklyn!\n",
      "\n",
      "Failed to get player Karstens, Anna Kate for Middle Tenn.!\n",
      "\n",
      "Failed to get player Goldstein, Madison for Rutgers!\n",
      "\n",
      "Failed to get player Haggerty, Maddie for Weber St.!\n",
      "\n",
      "Failed to get player Ballou, Dani for Grand Canyon!\n",
      "\n",
      "Failed to get player Hickman, Naomi for Appalachian St.!\n",
      "\n",
      "Failed to get player Schirmer, Brooklyn for Santa Clara!\n",
      "\n",
      "Failed to get player Williams, Kayla for Eastern Ill.!\n",
      "\n",
      "Failed to get player Jones, Lydia for Texas!\n",
      "\n",
      "Failed to get player Rippee, Rachel for Western Mich.!\n",
      "\n",
      "Failed to get player Williams, Aniya for Ohio St.!\n",
      "\n",
      "Failed to get player Nemeth, Rebekah for Cornell!\n",
      "\n",
      "Failed to get player Tingelhoff, Jade for UCLA!\n",
      "\n",
      "Failed to get player Hackett, Kailey for NJIT!\n",
      "\n",
      "Failed to get player Garcia, Briana for Colorado!\n",
      "\n",
      "Failed to get player Joseph, Sydney for La.-Monroe!\n",
      "\n",
      "Failed to get player Mitchell, Myca for Florida!\n",
      "\n",
      "Failed to get player Paris, Kendyl for Jacksonville!\n",
      "\n",
      "Failed to get player Hardig, Natalie for Xavier!\n",
      "\n",
      "Failed to get player Erwin, Katelyn for Alcorn!\n",
      "\n",
      "Failed to get player Aigner-Swesey, Carly for UTEP!\n",
      "\n",
      "Failed to get player Hembree, Maggie for Alabama St.!\n",
      "\n",
      "Failed to get player Dzubak, Emily for UT Arlington!\n",
      "\n",
      "Failed to get player Palmer, Anna for Creighton!\n",
      "\n",
      "Failed to get player Donahue, Jessica for Cal Poly!\n",
      "\n",
      "Failed to get player Boyd, Hannah for Akron!\n",
      "\n",
      "Failed to get player Anukwuem, Chino for Columbia!\n",
      "\n",
      "Failed to get player Svorinic, Victoria for Rice!\n",
      "\n",
      "Failed to get player O'Brien, Lauren for Central Ark.!\n",
      "\n",
      "Failed to get player Jackson, Tiana for Portland!\n",
      "\n",
      "Failed to get player Ford, Alyse for Nevada!\n",
      "\n",
      "Failed to get player Gallop, Sien for UAB!\n",
      "\n",
      "Failed to get player Dames, Cameron for Bethune-Cookman!\n",
      "\n",
      "Failed to get player Clark, Payten for Wofford!\n",
      "\n",
      "Failed to get player Hall, Kenza for Sacramento St.!\n",
      "\n",
      "Failed to get player Calvin, Lindsey for UMKC!\n",
      "\n",
      "Failed to get player Rocha, Camryn for Norfolk St.!\n",
      "\n",
      "Failed to get player Deobler, Nicole for Prairie View!\n",
      "\n",
      "Failed to get player Brown, Mikai for Georgetown!\n",
      "\n",
      "Failed to get player Floyd, Taylor for UNCW!\n",
      "\n",
      "Failed to get player Lawrence, Brittany for Charlotte!\n",
      "\n",
      "Failed to get player Nemeth, Anett for Austin Peay!\n",
      "\n",
      "Failed to get player Owen, Riley for UCF!\n",
      "\n",
      "Failed to get player Kolurbasi, Melissa for Bryant!\n",
      "\n",
      "Failed to get player Gibson, Taylor for UIC!\n",
      "\n",
      "Failed to get player Guice, Marlena for Cleveland St.!\n",
      "\n",
      "Failed to get player Carter, Kinley for Dayton!\n",
      "\n",
      "Failed to get player Baptista, Victoria for Troy!\n",
      "\n",
      "Failed to get player Gomez, Haley for Howard!\n",
      "\n",
      "Failed to get player Brown, Julia for CSU Bakersfield!\n",
      "\n",
      "Failed to get player Ikenegbu, Gloria for Pittsburgh!\n",
      "\n",
      "Failed to get player Templeton, Haley for Kent St.!\n",
      "\n",
      "Failed to get player Onosko, Cailin for Iowa!\n",
      "\n",
      "Failed to get player Shaw, Paige for Western Ky.!\n",
      "\n",
      "Failed to get player Rounsaville, Autumn for Southern Ill.!\n",
      "\n",
      "Failed to get player Waitsman, Faith for Illinois St.!\n",
      "\n",
      "Failed to get player Scanlan, Emma for South Alabama!\n",
      "\n",
      "Failed to get player Brown, April for Southern California!\n",
      "\n",
      "Failed to get player Baranski, Taylor for Virginia Tech!\n",
      "\n",
      "Failed to get player Raleigh, Emma for Tennessee St.!\n",
      "\n",
      "Failed to get player Frazier, Kaylee for Lamar University!\n",
      "\n",
      "Failed to get player Jordan, Khalia for Long Beach St.!\n",
      "\n",
      "Failed to get player Vazquez, Camila for Presbyterian!\n",
      "\n",
      "Failed to get player Wiedenfeld, Maddie for Fairleigh Dickinson!\n",
      "\n",
      "Failed to get player Crush, Megan for South Fla.!\n",
      "\n",
      "Failed to get player Fornoff, Keegan for South Carolina St.!\n",
      "\n",
      "Failed to get player Smith, Taylor for George Mason!\n",
      "\n",
      "Failed to get player Ajayi, Dani for Furman!\n",
      "\n",
      "Failed to get player Maher, Ashley for Auburn!\n",
      "\n",
      "Failed to get player Colwell, Kelly for Southern Utah!\n",
      "\n",
      "Failed to get player Wayne, Liz for Stetson!\n",
      "\n",
      "Failed to get player Otte, Dylynn for Purdue!\n",
      "\n",
      "Failed to get player Azore, Joilyn for Fairfield!\n",
      "\n",
      "Failed to get player Colombo, Sasha for Western Caro.!\n",
      "\n",
      "Failed to get player Petnicki, Olivia for Gardner-Webb!\n",
      "\n",
      "Failed to get player Lee, Lauren for UTRGV!\n",
      "\n",
      "Failed to get player Cummings, Ally for Green Bay!\n",
      "\n",
      "Failed to get player Cox, Corinnne for San Jose St.!\n",
      "\n",
      "Failed to get player Grant, Erica for Hartford!\n",
      "\n",
      "Failed to get player Roberts, Courtnie for Lipscomb!\n",
      "\n",
      "Failed to get player Smith, Amanda for Wright St.!\n",
      "\n",
      "Failed to get player Clapp, Bethany for Denver!\n",
      "\n",
      "Failed to get player Meyer, Maggie for Ball St.!\n",
      "\n",
      "Failed to get player Riner, Katelynn for Towson!\n",
      "\n",
      "Failed to get player Hoye, Cali for Southern U.!\n",
      "\n",
      "Failed to get player Ennis, Camryn for UConn!\n",
      "\n",
      "Failed to get player Furlong, Courtney for Northern Colo.!\n",
      "\n",
      "Failed to get player Pacheco, Mercedes for Portland St.!\n",
      "\n",
      "Failed to get player Bruder, Kylie for Northwestern St.!\n",
      "\n",
      "Failed to get player Barnes, Sanaa for Stony Brook!\n",
      "\n",
      "Failed to get player Espinoza, Catie for Miami!\n",
      "\n",
      "Failed to get player Mosher, Madeline for Albany!\n",
      "\n",
      "Failed to get player Mirich, Carter for Pepperdine!\n",
      "\n",
      "Failed to get player Fields, Kenzie for James Madison!\n",
      "\n",
      "Failed to get player Wild, Mackenzie for Texas Southern!\n",
      "\n",
      "Failed to get player Rudolph, Emily for A&M-Corpus Christi!\n",
      "\n",
      "Failed to get player Ruggiero, Katrina for Texas Tech!\n",
      "\n",
      "Failed to get player Hill, Micaiah for Yale!\n",
      "\n",
      "Failed to get player Giardina, Amanda for Loyola Marymount!\n",
      "\n",
      "Failed to get player Williams, Trinity for Holy Cross!\n",
      "\n",
      "Failed to get player Massab, Jordan for Jackson St.!\n",
      "\n",
      "Failed to get player Carey, Kate for Minnesota!\n",
      "\n",
      "Failed to get player Waggoner, Seyvion for San Diego St.!\n",
      "\n",
      "Failed to get player Jacobs, Casey for Maryland!\n",
      "\n",
      "Failed to get player Kuehn, Jenna for UC Irvine!\n",
      "\n",
      "Failed to get player Haynes, Maddie for Louisville!\n",
      "\n",
      "Failed to get player Mackeviciute, Gintare for Purdue Fort Wayne!\n",
      "\n",
      "Failed to get player Simpson, Madalon for Loyola Chicago!\n",
      "\n",
      "Failed to get player Voss, Taylor for FIU!\n",
      "\n",
      "Failed to get player Koumelis, Ali for Toledo!\n",
      "\n",
      "Failed to get player Brayboy, Annissa for South Carolina!\n",
      "\n",
      "Failed to get player Blatcher, Mack for Princeton!\n",
      "\n",
      "Failed to get player Filipiak, Kylie for High Point!\n",
      "\n",
      "Failed to get player Okino, Rika for Mississippi Val.!\n",
      "\n",
      "Failed to get player McMath, Melissa for North Florida!\n",
      "\n",
      "Failed to get player Norris, Emma for Utah!\n",
      "\n",
      "Failed to get player Petersen, Baylee for Saint Peter's!\n",
      "\n",
      "Failed to get player Gray, Serena for Belmont!\n",
      "\n",
      "Failed to get player Denham, Caylie for Georgia St.!\n",
      "\n",
      "Failed to get player Kurokawa, Kailee for Texas A&M!\n",
      "\n",
      "Failed to get player Simo, Savvy for Radford!\n",
      "\n",
      "Failed to get player Richardson, Payton for Savannah St.!\n",
      "\n",
      "Failed to get player Perosa, Avery for ETSU!\n",
      "\n",
      "Failed to get player Warnell, Nayo for Manhattan!\n",
      "\n",
      "Failed to get player Granado, Kayla for Youngstown St.!\n",
      "\n",
      "Failed to get player Brouker, Katherine for Chicago St.!\n",
      "\n",
      "Failed to get player Dame, Kabria for Air Force!\n",
      "\n",
      "Failed to get player Dunn, Kellen for Providence!\n",
      "\n",
      "Failed to get player Bates, Kalysia for South Dakota St.!\n",
      "\n",
      "Failed to get player Brown, Latrice for Central Mich.!\n",
      "\n",
      "Failed to get player Redmond, Elena for Loyola Maryland!\n",
      "\n",
      "Failed to get player Kane, Grace for St. John's!\n",
      "\n",
      "Failed to get player Dorn, Lexi for Kansas!\n",
      "\n",
      "Failed to get player Salvato, Carla for Charleston So.!\n",
      "\n",
      "Failed to get player Clarke, Shekinah for North Dakota St.!\n",
      "\n",
      "Failed to get player Heck, Hadley for VCU!\n",
      "\n",
      "Failed to get player Crews, Karen for Louisiana!\n",
      "\n",
      "Failed to get player Dim, Ivette for Morgan St.!\n",
      "\n",
      "Failed to get player Pernecky, Maddie for TCU!\n",
      "\n",
      "Failed to get player Sieck, Meredith for Harvard!\n",
      "\n",
      "Failed to get player Barry, Kelli for Wake Forest!\n",
      "\n",
      "Failed to get player Hansen, Emily for Lafayette!\n",
      "\n",
      "Failed to get player Lockin, Hannah for Louisiana Tech!\n",
      "\n",
      "Failed to get player Torres, Lexie for Ohio!\n",
      "\n",
      "Failed to get player Stone, Stephanie for Dartmouth!\n",
      "\n",
      "Failed to get player Passeck, Natalie for Hampton!\n",
      "\n",
      "Failed to get player Holland, Bridgette for Wyoming!\n",
      "\n",
      "Failed to get player Weidmann, Mikaela for New Mexico St.!\n",
      "\n",
      "Failed to get player Persons, Katie for Fresno St.!\n",
      "\n",
      "Failed to get player Holthaus, Rachel for Houston Baptist!\n",
      "\n",
      "Failed to get player Kallen, Julia for Buffalo!\n",
      "\n",
      "Failed to get player Fella, Maddie for Drake!\n",
      "\n",
      "Failed to get player Hart, Alexis for Penn!\n",
      "\n",
      "Failed to get player Westfield, Dana for Canisius!\n",
      "\n",
      "Failed to get player Jensen, Anna for Florida A&M!\n",
      "\n",
      "Failed to get player Elassal, Maya for Villanova!\n",
      "\n",
      "Failed to get player Durra, Jen for Duke!\n",
      "\n",
      "Failed to get player Hawkins, Brianna for Marshall!\n",
      "\n",
      "Failed to get player Grace, Phoebe for Tennessee Tech!\n",
      "\n",
      "Failed to get player Pick, Lauren for Quinnipiac!\n",
      "\n",
      "Failed to get player Waldrop, Belle for Southern Miss.!\n",
      "\n",
      "Failed to get player Hoffman, Courtney for Baylor!\n",
      "\n",
      "Failed to get player Allen, Camryn for DePaul!\n",
      "\n",
      "Failed to get player Hankinson, Clairissa for Pacific!\n",
      "\n",
      "Failed to get player Cerniauskaite, Kleja for La Salle!\n",
      "\n",
      "Failed to get player Pugh, Abby for Marist!\n",
      "\n",
      "Failed to get player Wright, Emillie for Texas St.!\n",
      "\n",
      "Failed to get player Marshall, Felicia for Arkansas!\n",
      "\n",
      "Failed to get player Moeller, Camryn for Delaware St.!\n",
      "\n",
      "Failed to get player Omwanghe, Nicole for Northern Ariz.!\n",
      "\n",
      "Failed to get player Falzone, Alexis for Ga. Southern!\n",
      "\n",
      "Failed to get player Cieslik, Kamila for Eastern Ky.!\n",
      "\n",
      "Failed to get player Bondar, Olena for North Carolina!\n",
      "\n",
      "Failed to get player Abu, Naghede for Northern Ill.!\n",
      "\n",
      "Failed to get player Oliver, Adria for Mississippi St.!\n",
      "\n",
      "Failed to get player Esposito, Sara for Delaware!\n",
      "\n",
      "Failed to get player Wright, Hannah for Morehead St.!\n",
      "\n",
      "Failed to get player Thornburg, Mackenzi for Southeast Mo. St.!\n",
      "\n",
      "Failed to get player Bentz, Abigail for Navy!\n",
      "\n",
      "Failed to get player Mortensen, Brianne for Memphis!\n",
      "\n",
      "Failed to get player Pe'a, Brooklen for Indiana St.!\n",
      "\n",
      "Failed to get player Shello, Alexa for San Diego!\n",
      "\n",
      "Failed to get player Villarreal, Cambree for Tulsa!\n",
      "\n",
      "Failed to get player Tuxford, Kylie for UMES!\n",
      "\n",
      "Failed to get player Garrison, Kylee for Oregon St.!\n",
      "\n",
      "Failed to get player Conley, Shelby for Gonzaga!\n",
      "\n",
      "Failed to get player Calloway, Gabby for Omaha!\n",
      "\n",
      "Failed to get player Reiser, Tori for UT Martin!\n",
      "\n",
      "Failed to get player Bradburn, Mahala for Grambling!\n",
      "\n",
      "Failed to get player Bartley, Sierra for South Dakota!\n",
      "\n",
      "Failed to get player Wenglikowski, Emily for Coppin St.!\n",
      "\n",
      "Failed to get player Kinley, Jaymeson for CSUN!\n",
      "\n",
      "Failed to get player Brister, Hannah for Seton Hall!\n",
      "\n",
      "Failed to get player Dixon, Emma for Notre Dame!\n",
      "\n",
      "Failed to get player Rodriguez-Hairston, De' Antionette for Alabama!\n",
      "\n",
      "Failed to get player Hunter, Kyra for Rider!\n",
      "\n",
      "Failed to get player Schneider, Haley for Michigan St.!\n",
      "\n",
      "Failed to get player Landeros, Joey for Missouri!\n",
      "\n",
      "Failed to get player Horn, Shanice for Colgate!\n",
      "\n",
      "Failed to get player Luckey, Nicole for Fordham!\n",
      "\n",
      "Failed to get player Dalton, Courtney for Niagara!\n",
      "\n",
      "Failed to get player Thomas, Kylie for Boston College!\n",
      "\n",
      "Failed to get player Hill, Brieanna for Samford!\n",
      "\n",
      "Failed to get player Gibson, Maggie for American!\n",
      "\n",
      "Failed to get player Bent, Sydney for Ark.-Pine Bluff!\n",
      "\n",
      "Failed to get player Uhr, Anna for Davidson!\n",
      "\n",
      "Failed to get player Kennel, Aleyna for East Carolina!\n",
      "\n",
      "Failed to get player Ianovale, Erika for Siena!\n",
      "\n",
      "Failed to get player Weideman, Lolo for UNI!\n",
      "\n",
      "Failed to get player Lete, Alexis for Idaho St.!\n",
      "\n",
      "Failed to get player Kocabiyik, Aybuke for Nebraska!\n",
      "\n",
      "Failed to get player Schwantz, Payton for Tulane!\n",
      "\n",
      "Failed to get player Malloy, Kamryn for Bucknell!\n",
      "\n",
      "Failed to get player Klinger, Ronja for UC Riverside!\n",
      "\n",
      "Failed to get player Brown, Whitney for North Texas!\n",
      "\n",
      "Failed to get player Hebert, Lexi for Arizona St.!\n",
      "\n",
      "Failed to get player Smith, Jamie for UNC Asheville!\n",
      "\n",
      "Failed to get player Varga, Julie for Southeastern La.!\n",
      "\n",
      "Failed to get player Proctor, Lindsay for Cal St. Fullerton!\n",
      "\n",
      "Failed to get player Manderson, Petra for Evansville!\n",
      "\n",
      "Failed to get player Mutiri, Gloria for George Washington!\n",
      "\n",
      "Failed to get player Stroud, Sydney for San Francisco!\n",
      "\n",
      "Failed to get player Lucero, Alex for New Mexico!\n",
      "\n",
      "Failed to get player Carrabine, Macy for Kennesaw St.!\n",
      "\n",
      "Failed to get player Coonan, Riley for Binghamton!\n",
      "\n",
      "Failed to get player Vujosevic, Iva for Saint Francis!\n",
      "\n",
      "Failed to get player Nelson, Katie for Sacred Heart!\n",
      "\n",
      "Failed to get player Inkret, Inka for Georgia!\n",
      "\n",
      "Failed to get player House, Elizabeth for Washington St.!\n",
      "\n",
      "Failed to get player Mahaffey, Danielle for Oakland!\n",
      "\n",
      "Failed to get player Miller, Monica for Utah St.!\n",
      "\n",
      "Failed to get player Burke, Mckenzie for UC Santa Barbara!\n",
      "\n",
      "Failed to get player Wagner, Kat for Eastern Wash.!\n",
      "\n",
      "Failed to get player MEYER, Katelyn for IUPUI!\n",
      "\n",
      "Failed to get player Watson, Hannah for Sam Houston St.!\n",
      "\n",
      "Failed to get player Rooney, Mason for Oregon!\n",
      "\n",
      "Failed to get player Finch, Gylian for New Hampshire!\n",
      "\n",
      "Failed to get player Estes, Mckena for Georgia Tech!\n",
      "\n",
      "Failed to get player Dunston, Amani for Illinois!\n",
      "\n",
      "Failed to get player Kuch, Madison for Oklahoma!\n",
      "\n",
      "Failed to get player Smith, Caitlyn for Iona!\n",
      "\n",
      "Failed to get player Miller, Megan for Chattanooga!\n",
      "\n",
      "Failed to get player Strong, Allie for Brown!\n",
      "\n",
      "Failed to get player Shamley, Johnna for Liberty!\n",
      "\n",
      "Failed to get player Fritsche, Kristen for UNC Greensboro!\n",
      "\n",
      "Failed to get player Cash, Alisah for Northern Ky.!\n",
      "\n",
      "Failed to get player Horton, Melody for Idaho!\n",
      "\n",
      "Failed to get player Leo, Gabby for St. Francis Brooklyn!\n",
      "\n",
      "Failed to get player Schomer, Camille for Colorado St.!\n",
      "\n",
      "Failed to get player Nelson, Haylee for Fla. Atlantic!\n",
      "\n",
      "Failed to get player Wood, Kalie for Elon!\n",
      "Done!\n",
      "Getting match wise dataframes ... Done!\n",
      "ipykernel_launcher:69: TqdmDeprecationWarning: Please use `tqdm.notebook.trange` instead of `tqdm.tnrange`\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Combining into single df', layout=Layou…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c5483ec9a794e9288ab4f7a4c7b51e0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'df_len': 0, 'err_a': 0, 'err_b': 0}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "combine_with_player(\n",
    "    player_input_path=\"/home/veds12/Desktop/Projects/volleyball-ml/data/ncaa/processed/2018/player_game_wise_0.2_ewm\",\n",
    "    team_stats_path=\"/home/veds12/Desktop/Projects/volleyball-ml/data/ncaa/raw/2018/team_stats\",\n",
    "    team_matches_path=\"/home/veds12/Desktop/Projects/volleyball-ml/data/ncaa/processed/2018/game_by_game_0.2_ewm\",\n",
    "    macthes_with_player_info_path=\"/home/veds12/Desktop/Projects/volleyball-ml/data/ncaa/processed/2018/game_by_game_with_players_0.2_ewm\",\n",
    "    combined_output_path=\"/home/veds12/Desktop/Projects/volleyball-ml/data/ncaa/processed/2018/accumulated/0.2_ewm_with_players.csv\",\n",
    ")"
   ]
  },
  {
   "source": [
    "# Cleaning file names in team_stats"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Brown.csv!\n",
      "UC Riverside (Big West).csv successfully renamed to UC Riverside.csv!\n",
      "Charlotte (C-USA).csv successfully renamed to Charlotte.csv!\n",
      "Northern Ariz. (Big Sky).csv successfully renamed to Northern Ariz..csv!\n",
      "Cleveland St. (Horizon).csv successfully renamed to Cleveland St..csv!\n",
      "Samford (SoCon).csv successfully renamed to Samford.csv!\n",
      "Utah St. (Mountain West).csv successfully renamed to Utah St..csv!\n",
      "UNCW (CAA).csv successfully renamed to UNCW.csv!\n",
      "East Carolina (AAC).csv successfully renamed to East Carolina.csv!\n",
      "Indiana St. (MVC).csv successfully renamed to Indiana St..csv!\n",
      "Binghamton (America East).csv successfully renamed to Binghamton.csv!\n",
      "UTRGV (WAC).csv successfully renamed to UTRGV.csv!\n",
      "N.C. A&T (MEAC).csv successfully renamed to N.C. A&T.csv!\n",
      "Northwestern (Big Ten).csv successfully renamed to Northwestern.csv!\n",
      "Green Bay (Horizon).csv successfully renamed to Green Bay.csv!\n",
      "Oklahoma (Big 12).csv successfully renamed to Oklahoma.csv!\n",
      "Boise St. (Mountain West).csv successfully renamed to Boise St..csv!\n",
      "UMES (MEAC).csv successfully renamed to UMES.csv!\n",
      "CSUN (Big West).csv successfully renamed to CSUN.csv!\n",
      "Fairleigh Dickinson (NEC).csv successfully renamed to Fairleigh Dickinson.csv!\n",
      "Santa Clara (WCC).csv successfully renamed to Santa Clara.csv!\n",
      "DePaul (Big East).csv successfully renamed to DePaul.csv!\n",
      "Saint Peter's (MAAC).csv successfully renamed to Saint Peter's.csv!\n",
      "Sacramento St. (Big Sky).csv successfully renamed to Sacramento St..csv!\n",
      "Saint Francis (PA) (NEC).csv successfully renamed to Saint Francis.csv!\n",
      "Cornell (Ivy League).csv successfully renamed to Cornell.csv!\n",
      "Sacred Heart (NEC).csv successfully renamed to Sacred Heart.csv!\n",
      "UTSA (C-USA).csv successfully renamed to UTSA.csv!\n",
      "Central Conn. St. (NEC).csv successfully renamed to Central Conn. St..csv!\n",
      "Southern Utah (Big Sky).csv successfully renamed to Southern Utah.csv!\n",
      "Boston College (ACC).csv successfully renamed to Boston College.csv!\n",
      "Purdue (Big Ten).csv successfully renamed to Purdue.csv!\n",
      "Pepperdine (WCC).csv successfully renamed to Pepperdine.csv!\n",
      "LSU (SEC).csv successfully renamed to LSU.csv!\n",
      "Louisville (ACC).csv successfully renamed to Louisville.csv!\n",
      "Syracuse (ACC).csv successfully renamed to Syracuse.csv!\n",
      "Miami (OH) (MAC).csv successfully renamed to Miami.csv!\n",
      "New Mexico St. (WAC).csv successfully renamed to New Mexico St..csv!\n",
      "Houston (AAC).csv successfully renamed to Houston.csv!\n",
      "Middle Tenn. (C-USA).csv successfully renamed to Middle Tenn..csv!\n",
      "Jacksonville St. (OVC).csv successfully renamed to Jacksonville St..csv!\n",
      "Charleston So. (Big South).csv successfully renamed to Charleston So..csv!\n",
      "James Madison (CAA).csv successfully renamed to James Madison.csv!\n",
      "San Jose St. (Mountain West).csv successfully renamed to San Jose St..csv!\n",
      "Western Caro. (SoCon).csv successfully renamed to Western Caro..csv!\n",
      "Oregon (Pac-12).csv successfully renamed to Oregon.csv!\n",
      "Sam Houston St. (Southland).csv successfully renamed to Sam Houston St..csv!\n",
      "Norfolk St. (MEAC).csv successfully renamed to Norfolk St..csv!\n",
      "Washington St. (Pac-12).csv successfully renamed to Washington St..csv!\n",
      "FGCU (ASUN).csv successfully renamed to FGCU.csv!\n",
      "Nevada (Mountain West).csv successfully renamed to Nevada.csv!\n",
      "Delaware St. (MEAC).csv successfully renamed to Delaware St..csv!\n",
      "Providence (Big East).csv successfully renamed to Providence.csv!\n",
      "Idaho (Big Sky).csv successfully renamed to Idaho.csv!\n",
      "Texas Tech (Big 12).csv successfully renamed to Texas Tech.csv!\n",
      "Albany (NY) (America East).csv successfully renamed to Albany.csv!\n",
      "Missouri (SEC).csv successfully renamed to Missouri.csv!\n",
      "St. Francis Brooklyn (NEC).csv successfully renamed to St. Francis Brooklyn.csv!\n",
      "TCU (Big 12).csv successfully renamed to TCU.csv!\n",
      "Eastern Wash. (Big Sky).csv successfully renamed to Eastern Wash..csv!\n",
      "Montana (Big Sky).csv successfully renamed to Montana.csv!\n",
      "South Alabama (Sun Belt).csv successfully renamed to South Alabama.csv!\n",
      "Western Ky. (C-USA).csv successfully renamed to Western Ky..csv!\n",
      "Loyola Chicago (MVC).csv successfully renamed to Loyola Chicago.csv!\n",
      "St. John's (NY) (Big East).csv successfully renamed to St. John's.csv!\n",
      "Michigan (Big Ten).csv successfully renamed to Michigan.csv!\n",
      "Fla. Atlantic (C-USA).csv successfully renamed to Fla. Atlantic.csv!\n",
      "UC Davis (Big West).csv successfully renamed to UC Davis.csv!\n",
      "Georgia (SEC).csv successfully renamed to Georgia.csv!\n",
      "Penn (Ivy League).csv successfully renamed to Penn.csv!\n",
      "Michigan St. (Big Ten).csv successfully renamed to Michigan St..csv!\n",
      "Kennesaw St. (ASUN).csv successfully renamed to Kennesaw St..csv!\n",
      "Creighton (Big East).csv successfully renamed to Creighton.csv!\n",
      "Southern California (Pac-12).csv successfully renamed to Southern California.csv!\n",
      "North Dakota (Summit League).csv successfully renamed to North Dakota.csv!\n",
      "Quinnipiac (MAAC).csv successfully renamed to Quinnipiac.csv!\n",
      "Arkansas (SEC).csv successfully renamed to Arkansas.csv!\n",
      "SFA (Southland).csv successfully renamed to SFA.csv!\n",
      "Yale (Ivy League).csv successfully renamed to Yale.csv!\n",
      "UNLV (Mountain West).csv successfully renamed to UNLV.csv!\n",
      "Cincinnati (AAC).csv successfully renamed to Cincinnati.csv!\n",
      "UNC Asheville (Big South).csv successfully renamed to UNC Asheville.csv!\n",
      "UCF (AAC).csv successfully renamed to UCF.csv!\n",
      "Alcorn (SWAC).csv successfully renamed to Alcorn.csv!\n",
      "Wake Forest (ACC).csv successfully renamed to Wake Forest.csv!\n",
      "Kentucky (SEC).csv successfully renamed to Kentucky.csv!\n",
      "New Mexico (Mountain West).csv successfully renamed to New Mexico.csv!\n",
      "Northern Ky. (Horizon).csv successfully renamed to Northern Ky..csv!\n",
      "Weber St. (Big Sky).csv successfully renamed to Weber St..csv!\n",
      "Long Beach St. (Big West).csv successfully renamed to Long Beach St..csv!\n",
      "Tulsa (AAC).csv successfully renamed to Tulsa.csv!\n",
      "Memphis (AAC).csv successfully renamed to Memphis.csv!\n",
      "Northeastern (CAA).csv successfully renamed to Northeastern.csv!\n",
      "Virginia (ACC).csv successfully renamed to Virginia.csv!\n",
      "Arizona (Pac-12).csv successfully renamed to Arizona.csv!\n",
      "Florida St. (ACC).csv successfully renamed to Florida St..csv!\n",
      "Arizona St. (Pac-12).csv successfully renamed to Arizona St..csv!\n",
      "Saint Louis (Atlantic 10).csv successfully renamed to Saint Louis.csv!\n",
      "Princeton (Ivy League).csv successfully renamed to Princeton.csv!\n",
      "Alabama St. (SWAC).csv successfully renamed to Alabama St..csv!\n",
      "Manhattan (MAAC).csv successfully renamed to Manhattan.csv!\n",
      "Saint Mary's (CA) (WCC).csv successfully renamed to Saint Mary's.csv!\n",
      "Siena (MAAC).csv successfully renamed to Siena.csv!\n",
      "Abilene Christian (Southland).csv successfully renamed to Abilene Christian.csv!\n",
      "Belmont (OVC).csv successfully renamed to Belmont.csv!\n",
      "Northern Colo. (Big Sky).csv successfully renamed to Northern Colo..csv!\n",
      "Little Rock (Sun Belt).csv successfully renamed to Little Rock.csv!\n",
      "Kent St. (MAC).csv successfully renamed to Kent St..csv!\n",
      "Wright St. (Horizon).csv successfully renamed to Wright St..csv!\n",
      "Kansas City (WAC).csv successfully renamed to Kansas City.csv!\n",
      "Coppin St. (MEAC).csv successfully renamed to Coppin St..csv!\n",
      "Jackson St. (SWAC).csv successfully renamed to Jackson St..csv!\n",
      "Liberty (ASUN).csv successfully renamed to Liberty.csv!\n",
      "Ark.-Pine Bluff (SWAC).csv successfully renamed to Ark.-Pine Bluff.csv!\n",
      "William & Mary (CAA).csv successfully renamed to William & Mary.csv!\n",
      "USC Upstate (Big South).csv successfully renamed to USC Upstate.csv!\n",
      "Miami (FL) (ACC).csv successfully renamed to Miami.csv!\n",
      "Washington (Pac-12).csv successfully renamed to Washington.csv!\n",
      "Mississippi St. (SEC).csv successfully renamed to Mississippi St..csv!\n",
      "Texas (Big 12).csv successfully renamed to Texas.csv!\n",
      "Portland (WCC).csv successfully renamed to Portland.csv!\n",
      "Texas Southern (SWAC).csv successfully renamed to Texas Southern.csv!\n",
      "Iowa St. (Big 12).csv successfully renamed to Iowa St..csv!\n",
      "Bradley (MVC).csv successfully renamed to Bradley.csv!\n",
      "NC State (ACC).csv successfully renamed to NC State.csv!\n",
      "Tennessee St. (OVC).csv successfully renamed to Tennessee St..csv!\n",
      "Canisius (MAAC).csv successfully renamed to Canisius.csv!\n",
      "New Hampshire (America East).csv successfully renamed to New Hampshire.csv!\n",
      "American (Patriot).csv successfully renamed to American.csv!\n",
      "Southeast Mo. St. (OVC).csv successfully renamed to Southeast Mo. St..csv!\n",
      "Eastern Ill. (OVC).csv successfully renamed to Eastern Ill..csv!\n",
      "Southern Miss. (C-USA).csv successfully renamed to Southern Miss..csv!\n",
      "Lipscomb (ASUN).csv successfully renamed to Lipscomb.csv!\n",
      "Houston Baptist (Southland).csv successfully renamed to Houston Baptist.csv!\n",
      "Duquesne (Atlantic 10).csv successfully renamed to Duquesne.csv!\n",
      "SIUE (OVC).csv successfully renamed to SIUE.csv!\n",
      "Mississippi Val. (SWAC).csv successfully renamed to Mississippi Val..csv!\n",
      "North Texas (C-USA).csv successfully renamed to North Texas.csv!\n",
      "Valparaiso (MVC).csv successfully renamed to Valparaiso.csv!\n",
      "Colorado St. (Mountain West).csv successfully renamed to Colorado St..csv!\n",
      "Dartmouth (Ivy League).csv successfully renamed to Dartmouth.csv!\n",
      "Tennessee Tech (OVC).csv successfully renamed to Tennessee Tech.csv!\n",
      "Delaware (CAA).csv successfully renamed to Delaware.csv!\n",
      "Colgate (Patriot).csv successfully renamed to Colgate.csv!\n",
      "Omaha (Summit League).csv successfully renamed to Omaha.csv!\n",
      "Ga. Southern (Sun Belt).csv successfully renamed to Ga. Southern.csv!\n",
      "Iowa (Big Ten).csv successfully renamed to Iowa.csv!\n",
      "Kansas (Big 12).csv successfully renamed to Kansas.csv!\n",
      "South Carolina (SEC).csv successfully renamed to South Carolina.csv!\n",
      "Illinois (Big Ten).csv successfully renamed to Illinois.csv!\n",
      "Villanova (Big East).csv successfully renamed to Villanova.csv!\n",
      "George Mason (Atlantic 10).csv successfully renamed to George Mason.csv!\n",
      "Marquette (Big East).csv successfully renamed to Marquette.csv!\n",
      "Louisiana Tech (C-USA).csv successfully renamed to Louisiana Tech.csv!\n",
      "Arkansas St. (Sun Belt).csv successfully renamed to Arkansas St..csv!\n",
      "Bryant (NEC).csv successfully renamed to Bryant.csv!\n",
      "UAB (C-USA).csv successfully renamed to UAB.csv!\n",
      "Lafayette (Patriot).csv successfully renamed to Lafayette.csv!\n",
      "Bethune-Cookman (MEAC).csv successfully renamed to Bethune-Cookman.csv!\n",
      "Tulane (AAC).csv successfully renamed to Tulane.csv!\n",
      "Presbyterian (Big South).csv successfully renamed to Presbyterian.csv!\n",
      "Oakland (Horizon).csv successfully renamed to Oakland.csv!\n",
      "Western Mich. (MAC).csv successfully renamed to Western Mich..csv!\n",
      "Rice (C-USA).csv successfully renamed to Rice.csv!\n",
      "North Carolina (ACC).csv successfully renamed to North Carolina.csv!\n",
      "Gonzaga (WCC).csv successfully renamed to Gonzaga.csv!\n",
      "California (Pac-12).csv successfully renamed to California.csv!\n",
      "UT Martin (OVC).csv successfully renamed to UT Martin.csv!\n",
      "Coastal Carolina (Sun Belt).csv successfully renamed to Coastal Carolina.csv!\n",
      "VCU (Atlantic 10).csv successfully renamed to VCU.csv!\n",
      "Texas A&M (SEC).csv successfully renamed to Texas A&M.csv!\n",
      "UC Irvine (Big West).csv successfully renamed to UC Irvine.csv!\n",
      "South Carolina St. (MEAC).csv successfully renamed to South Carolina St..csv!\n",
      "A&M-Corpus Christi (Southland).csv successfully renamed to A&M-Corpus Christi.csv!\n",
      "Hawaii (Big West).csv successfully renamed to Hawaii.csv!\n",
      "Appalachian St. (Sun Belt).csv successfully renamed to Appalachian St..csv!\n",
      "Western Ill. (Summit League).csv successfully renamed to Western Ill..csv!\n",
      "UNI (MVC).csv successfully renamed to UNI.csv!\n",
      "Penn St. (Big Ten).csv successfully renamed to Penn St..csv!\n",
      "Hofstra (CAA).csv successfully renamed to Hofstra.csv!\n",
      "Seattle U (WAC).csv successfully renamed to Seattle U.csv!\n",
      "Stanford (Pac-12).csv successfully renamed to Stanford.csv!\n",
      "UCLA (Pac-12).csv successfully renamed to UCLA.csv!\n",
      "San Diego St. (Mountain West).csv successfully renamed to San Diego St..csv!\n",
      "South Dakota St. (Summit League).csv successfully renamed to South Dakota St..csv!\n",
      "Pittsburgh (ACC).csv successfully renamed to Pittsburgh.csv!\n",
      "Ole Miss (SEC).csv successfully renamed to Ole Miss.csv!\n",
      "Texas St. (Sun Belt).csv successfully renamed to Texas St..csv!\n",
      "Cal Poly (Big West).csv successfully renamed to Cal Poly.csv!\n",
      "Grambling (SWAC).csv successfully renamed to Grambling.csv!\n",
      "Central Ark. (Southland).csv successfully renamed to Central Ark..csv!\n",
      "Morgan St. (MEAC).csv successfully renamed to Morgan St..csv!\n",
      "Prairie View (SWAC).csv successfully renamed to Prairie View.csv!\n",
      "Evansville (MVC).csv successfully renamed to Evansville.csv!\n",
      "Campbell (Big South).csv successfully renamed to Campbell.csv!\n",
      "Georgia Tech (ACC).csv successfully renamed to Georgia Tech.csv!\n",
      "UIC (Horizon).csv successfully renamed to UIC.csv!\n",
      "Oregon St. (Pac-12).csv successfully renamed to Oregon St..csv!\n",
      "Portland St. (Big Sky).csv successfully renamed to Portland St..csv!\n",
      "Alabama (SEC).csv successfully renamed to Alabama.csv!\n",
      "Lamar University (Southland).csv successfully renamed to Lamar University.csv!\n",
      "SMU (AAC).csv successfully renamed to SMU.csv!\n",
      "Alabama A&M (SWAC).csv successfully renamed to Alabama A&M.csv!\n",
      "San Diego (WCC).csv successfully renamed to San Diego.csv!\n",
      "CSU Bakersfield (WAC).csv successfully renamed to CSU Bakersfield.csv!\n",
      "Baylor (Big 12).csv successfully renamed to Baylor.csv!\n",
      "Southeastern La. (Southland).csv successfully renamed to Southeastern La..csv!\n",
      "Marist (MAAC).csv successfully renamed to Marist.csv!\n",
      "Montana St. (Big Sky).csv successfully renamed to Montana St..csv!\n",
      "Bucknell (Patriot).csv successfully renamed to Bucknell.csv!\n",
      "UNC Greensboro (SoCon).csv successfully renamed to UNC Greensboro.csv!\n",
      "Auburn (SEC).csv successfully renamed to Auburn.csv!\n",
      "Murray St. (OVC).csv successfully renamed to Murray St..csv!\n",
      "Fairfield (MAAC).csv successfully renamed to Fairfield.csv!\n",
      "Morehead St. (OVC).csv successfully renamed to Morehead St..csv!\n",
      "Minnesota (Big Ten).csv successfully renamed to Minnesota.csv!\n",
      "Temple (AAC).csv successfully renamed to Temple.csv!\n",
      "Ball St. (MAC).csv successfully renamed to Ball St..csv!\n",
      "The Citadel (SoCon).csv successfully renamed to The Citadel.csv!\n",
      "LMU (CA) (WCC).csv successfully renamed to LMU.csv!\n",
      "Akron (MAC).csv successfully renamed to Akron.csv!\n",
      "Southern U. (SWAC).csv successfully renamed to Southern U..csv!\n",
      "Utah (Pac-12).csv successfully renamed to Utah.csv!\n",
      "Rhode Island (Atlantic 10).csv successfully renamed to Rhode Island.csv!\n",
      "Troy (Sun Belt).csv successfully renamed to Troy.csv!\n",
      "Furman (SoCon).csv successfully renamed to Furman.csv!\n",
      "Towson (CAA).csv successfully renamed to Towson.csv!\n",
      "Eastern Ky. (OVC).csv successfully renamed to Eastern Ky..csv!\n",
      "Milwaukee (Horizon).csv successfully renamed to Milwaukee.csv!\n",
      "Wichita St. (AAC).csv successfully renamed to Wichita St..csv!\n",
      "Niagara (MAAC).csv successfully renamed to Niagara.csv!\n",
      "Cal St. Fullerton (Big West).csv successfully renamed to Cal St. Fullerton.csv!\n",
      "Ohio St. (Big Ten).csv successfully renamed to Ohio St..csv!\n",
      "UC Santa Barbara (Big West).csv successfully renamed to UC Santa Barbara.csv!\n",
      "Toledo (MAC).csv successfully renamed to Toledo.csv!\n",
      "Rutgers (Big Ten).csv successfully renamed to Rutgers.csv!\n",
      "San Francisco (WCC).csv successfully renamed to San Francisco.csv!\n",
      "Colorado (Pac-12).csv successfully renamed to Colorado.csv!\n",
      "Clemson (ACC).csv successfully renamed to Clemson.csv!\n",
      "ETSU (SoCon).csv successfully renamed to ETSU.csv!\n",
      "Lehigh (Patriot).csv successfully renamed to Lehigh.csv!\n",
      "High Point (Big South).csv successfully renamed to High Point.csv!\n",
      "Maryland (Big Ten).csv successfully renamed to Maryland.csv!\n",
      "Utah Valley (WAC).csv successfully renamed to Utah Valley.csv!\n",
      "Youngstown St. (Horizon).csv successfully renamed to Youngstown St..csv!\n",
      "Rider (MAAC).csv successfully renamed to Rider.csv!\n",
      "Missouri St. (MVC).csv successfully renamed to Missouri St..csv!\n",
      "Radford (Big South).csv successfully renamed to Radford.csv!\n",
      "Gardner-Webb (Big South).csv successfully renamed to Gardner-Webb.csv!\n",
      "Marshall (C-USA).csv successfully renamed to Marshall.csv!\n",
      "Hampton (Big South).csv successfully renamed to Hampton.csv!\n",
      "Jacksonville (ASUN).csv successfully renamed to Jacksonville.csv!\n",
      "Idaho St. (Big Sky).csv successfully renamed to Idaho St..csv!\n",
      "Fresno St. (Mountain West).csv successfully renamed to Fresno St..csv!\n",
      "Central Mich. (MAC).csv successfully renamed to Central Mich..csv!\n",
      "Austin Peay (OVC).csv successfully renamed to Austin Peay.csv!\n",
      "Northwestern St. (Southland).csv successfully renamed to Northwestern St..csv!\n",
      "North Florida (ASUN).csv successfully renamed to North Florida.csv!\n",
      "New Orleans (Southland).csv successfully renamed to New Orleans.csv!\n",
      "McNeese (Southland).csv successfully renamed to McNeese.csv!\n",
      "UIW (Southland).csv successfully renamed to UIW.csv!\n",
      "Fordham (Atlantic 10).csv successfully renamed to Fordham.csv!\n",
      "LIU (NEC).csv successfully renamed to LIU.csv!\n",
      "Butler (Big East).csv successfully renamed to Butler.csv!\n",
      "Chicago St. (WAC).csv successfully renamed to Chicago St..csv!\n",
      "BYU (WCC).csv successfully renamed to BYU.csv!\n",
      "Howard (MEAC).csv successfully renamed to Howard.csv!\n",
      "Virginia Tech (ACC).csv successfully renamed to Virginia Tech.csv!\n",
      "Wyoming (Mountain West).csv successfully renamed to Wyoming.csv!\n",
      "Nicholls St. (Southland).csv successfully renamed to Nicholls St..csv!\n",
      "IUPUI (Horizon).csv successfully renamed to IUPUI.csv!\n",
      "Notre Dame (ACC).csv successfully renamed to Notre Dame.csv!\n",
      "Harvard (Ivy League).csv successfully renamed to Harvard.csv!\n",
      "N.C. Central (MEAC).csv successfully renamed to N.C. Central.csv!\n",
      "South Dakota (Summit League).csv successfully renamed to South Dakota.csv!\n",
      "George Washington (Atlantic 10).csv successfully renamed to George Washington.csv!\n",
      "Florida A&M (MEAC).csv successfully renamed to Florida A&M.csv!\n",
      "Duke (ACC).csv successfully renamed to Duke.csv!\n",
      "Indiana (Big Ten).csv successfully renamed to Indiana.csv!\n",
      "FIU (C-USA).csv successfully renamed to FIU.csv!\n",
      "Robert Morris (NEC).csv successfully renamed to Robert Morris.csv!\n",
      "Louisiana (Sun Belt).csv successfully renamed to Louisiana.csv!\n",
      "Iona (MAAC).csv successfully renamed to Iona.csv!\n",
      "Stetson (ASUN).csv successfully renamed to Stetson.csv!\n",
      "West Virginia (Big 12).csv successfully renamed to West Virginia.csv!\n",
      "UT Arlington (Sun Belt).csv successfully renamed to UT Arlington.csv!\n",
      "Kansas St. (Big 12).csv successfully renamed to Kansas St..csv!\n",
      "Georgia St. (Sun Belt).csv successfully renamed to Georgia St..csv!\n",
      "Hartford (America East).csv successfully renamed to Hartford.csv!\n",
      "Denver (Summit League).csv successfully renamed to Denver.csv!\n",
      "Wofford (SoCon).csv successfully renamed to Wofford.csv!\n",
      "Georgetown (Big East).csv successfully renamed to Georgetown.csv!\n",
      "Ohio (MAC).csv successfully renamed to Ohio.csv!\n",
      "Oral Roberts (Summit League).csv successfully renamed to Oral Roberts.csv!\n",
      "Dayton (Atlantic 10).csv successfully renamed to Dayton.csv!\n",
      "Tennessee (SEC).csv successfully renamed to Tennessee.csv!\n",
      "Illinois St. (MVC).csv successfully renamed to Illinois St..csv!\n",
      "North Dakota St. (Summit League).csv successfully renamed to North Dakota St..csv!\n",
      "Southern Ill. (MVC).csv successfully renamed to Southern Ill..csv!\n",
      "Bowling Green (MAC).csv successfully renamed to Bowling Green.csv!\n",
      "Buffalo (MAC).csv successfully renamed to Buffalo.csv!\n",
      "Davidson (Atlantic 10).csv successfully renamed to Davidson.csv!\n",
      "Chattanooga (SoCon).csv successfully renamed to Chattanooga.csv!\n",
      "Xavier (Big East).csv successfully renamed to Xavier.csv!\n",
      "Col. of Charleston (CAA).csv successfully renamed to Col. of Charleston.csv!\n",
      "La Salle (Atlantic 10).csv successfully renamed to La Salle.csv!\n",
      "Drake (MVC).csv successfully renamed to Drake.csv!\n",
      "Nebraska (Big Ten).csv successfully renamed to Nebraska.csv!\n",
      "Army West Point (Patriot).csv successfully renamed to Army West Point.csv!\n",
      "Holy Cross (Patriot).csv successfully renamed to Holy Cross.csv!\n",
      "UTEP (C-USA).csv successfully renamed to UTEP.csv!\n",
      "Loyola Maryland (Patriot).csv successfully renamed to Loyola Maryland.csv!\n",
      "Grand Canyon (WAC).csv successfully renamed to Grand Canyon.csv!\n",
      "Pacific (WCC).csv successfully renamed to Pacific.csv!\n",
      "Eastern Mich. (MAC).csv successfully renamed to Eastern Mich..csv!\n",
      "Columbia (Ivy League).csv successfully renamed to Columbia.csv!\n",
      "Elon (CAA).csv successfully renamed to Elon.csv!\n"
     ]
    }
   ],
   "source": [
    "year = 2019\n",
    "for root, _, files in os.walk(f'../../data/ncaa/raw/{year}/team_stats/'):\n",
    "    for f in files:\n",
    "        f_new = f[:f.find('(') - 1] + \".csv\"\n",
    "        os.rename(Path(root).joinpath(f), Path(root).joinpath(f_new))\n",
    "        print(f\"{f} successfully renamed to {f_new}!\")\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Combining(w.r.t. years) Data of all the years"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "data_path = \"../../data/ncaa\"\n",
    "years = [2019, 2018, 2017, 2016]\n",
    "outpath = Path(data_path).joinpath(\"combined\")\n",
    "acc = outpath.joinpath(\"accumulated\")\n",
    "acc.mkdir(parents=True, exist_ok=True)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "source": [
    "## Combined(w.r.t. years) game by game vanilla"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Compiled yearwise data into a single data file\n Size of final dataframe : 1167150\n"
     ]
    }
   ],
   "source": [
    "df_matches_gathered = [pd.read_csv(Path(data_path).joinpath(f\"processed/{year}/accumulated/matches_gathered.csv\")) for year in years]\n",
    "\n",
    "df_team_v_team_combined = pd.concat(df_matches_gathered, ignore_index=True)\n",
    "df_team_v_team_combined.to_csv(outpath.joinpath(\"accumulated/team_v_team.csv\"))\n",
    "print(f\"Compiled yearwise data into a single data file\\n Size of final dataframe : {df_team_v_team_combined.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "295523\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(Path(data_path).joinpath(\"processed/2019/accumulated/matches_gathered.csv\"))\n",
    "print(df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Failed to process data for LIU.csv\n",
      "Failed to process data for LMU.csv\n",
      "Failed to process data for Abilene Christian.csv\n",
      "Failed to process data for Grand Canyon.csv\n",
      "Failed to process data for Coastal Carolina.csv\n",
      "Failed to process data for Kansas City.csv\n",
      "Failed to process data for South Carolina St..csv\n",
      "Failed to process data for Saint Peter's.csv\n",
      "Failed to process data for UIW.csv\n"
     ]
    }
   ],
   "source": [
    "root_path = Path(data_path).joinpath(\"processed/2019/game_by_game_cleaned\")\n",
    "failed = []\n",
    "for root, _, files in os.walk(root_path):\n",
    "    for f in files:\n",
    "        try:\n",
    "            df_list = [pd.read_csv(Path(root).parent.parent.joinpath(f\"{year}/game_by_game_cleaned/{f}\")) for year in years]\n",
    "            df_team = pd.concat(df_list, ignore_index=True)\n",
    "            game_by_game_cleaned_path = Path(root).parent.parent.parent.joinpath(\"combined/game_by_game_cleaned_combined/\")\n",
    "            game_by_game_cleaned_path.mkdir(parents=True, exist_ok=True)\n",
    "            df_team.to_csv(game_by_game_cleaned_path.joinpath(f), index=False)\n",
    "        except:\n",
    "            print(f\"Failed to process data for {f}\")\n",
    "            failed.append(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done!\nDone!\n"
     ]
    }
   ],
   "source": [
    "LIU = [\"LIU.csv\", \"LIU Brooklyn.csv\", \"LIU Brooklyn.csv\", \"LIU.csv\"]\n",
    "CoastalCarolina = [\"Coastal Carolina.csv\", \"Coastal Caro..csv\", \"Coastal Caro..csv\", \"Coastal Carolina.csv\"]\n",
    "\n",
    "tuple1 = zip(CoastalCarolina, years)\n",
    "df_list = [pd.read_csv(Path(data_path).joinpath(f\"processed/{tuple_[1]}/game_by_game_cleaned/{tuple_[0]}\")) for tuple_ in tuple1]\n",
    "df_team = pd.concat(df_list, ignore_index=True)\n",
    "game_by_game_cleaned_path = Path(data_path).joinpath(f\"combined/game_by_game_cleaned_combined/Coastal Carolina.csv\")\n",
    "df_team.to_csv(game_by_game_cleaned_path, index=False)\n",
    "print(\"Done!\")\n",
    "\n",
    "tuple1 = zip(LIU, years)\n",
    "df_list = [pd.read_csv(Path(data_path).joinpath(f\"processed/{tuple_[1]}/game_by_game_cleaned/{tuple_[0]}\")) for tuple_ in tuple1]\n",
    "df_team = pd.concat(df_list, ignore_index=True)\n",
    "game_by_game_cleaned_path = Path(data_path).joinpath(f\"combined/game_by_game_cleaned_combined/LIU.csv\")\n",
    "df_team.to_csv(game_by_game_cleaned_path, index=False)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_team_data(input_dir, output_dir, tf):\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        new_root = Path(output_dir)\n",
    "        new_root.mkdir(parents=True, exist_ok=True)\n",
    "        for f in files:\n",
    "            df = pd.read_csv(Path(root).joinpath(f))\n",
    "            tf(df)\n",
    "            df.to_csv(new_root.joinpath(f), index=False)\n",
    "\n",
    "features = [\"Kills\", \"Errors\", \"Total Attacks\", \"Hit Pct\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\", \"PTS\"]"
   ]
  },
  {
   "source": [
    "## Combined(w.r.t. years) SMA Game by Game"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 10\n",
    "\n",
    "def sma(df):\n",
    "    df[features] = df[features].rolling(window, min_periods=1).mean()\n",
    "\n",
    "transform_team_data(\n",
    "    input_dir=f'../../data/ncaa/combined/game_by_game_cleaned_combined',\n",
    "    output_dir=f'../../data/ncaa/combined/game_by_game_{window}_sma_combined',\n",
    "    tf=sma,\n",
    ")\n"
   ]
  },
  {
   "source": [
    "## Combined(w.r.t. years) game by game CMA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cma(df):\n",
    "    df[features] = df[features].expanding().mean()\n",
    "\n",
    "transform_team_data(\n",
    "    input_dir=f'../../data/ncaa/combined/game_by_game_cleaned_combined',\n",
    "    output_dir=f'../../data/ncaa/combined/game_by_game_cma_combined',\n",
    "    tf=cma,\n",
    ")"
   ]
  },
  {
   "source": [
    "## Combined(w.r.t. years) game by game EWM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "\n",
    "def ewm(df):\n",
    "    df[features] = df[features].ewm(alpha=alpha).mean()\n",
    "\n",
    "transform_team_data(\n",
    "    input_dir=f'../../data/ncaa/combined/game_by_game_cleaned_combined',\n",
    "    output_dir=f'../../data/ncaa/combined/game_by_game_{alpha}_ewm_combined',\n",
    "    tf=ewm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    name = name.replace('\\\"', '')\n",
    "    if '@' in name:\n",
    "        if name.index('@') == 0:\n",
    "            return name[2:]\n",
    "        else:\n",
    "            return name[:name.index('@')-1]\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "features = [\"Kills\", \"Errors\", \"Total Attacks\", \"Hit Pct\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\", \"PTS\"]\n",
    "combined_features = [\"Date\", \"TeamA\", \"TeamB\", \"Result\", \"S\", \"Team A Kills\", \"Team A Errors\", \"Team A Total Attacks\", \"Team A Hit Pct\", \"Team A Assists\", \"Team A Aces\", \"Team A SErr\", \"Team A Digs\", \"Team A RErr\", \"Team A Block Solos\", \"Team A Block Assists\", \"Team A BErr\", \"Team A PTS\", \"Team B Kills\", \"Team B Errors\", \"Team B Total Attacks\", \"Team B Hit Pct\", \"Team B Assists\", \"Team B Aces\", \"Team B SErr\", \"Team B Digs\", \"Team B RErr\", \"Team B Block Solos\", \"Team B Block Assists\", \"Team B BErr\", \"Team B PTS\"]\n",
    "\n",
    "def combine(input_path, output_path):\n",
    "    print(\"Combining data directly for team matches ...\", end=' ')\n",
    "    dfs = []\n",
    "    team_names = []\n",
    "    for root, dirs, files in os.walk(input_path):\n",
    "        for f in files:\n",
    "            team_names.append(f[:-4])\n",
    "            dfs.append(pd.read_csv(Path(root).joinpath(f)))\n",
    "\n",
    "    data = []\n",
    "\n",
    "    err_a = 0\n",
    "    err_b = 0\n",
    "\n",
    "    for i, name in enumerate(team_names):\n",
    "        df = dfs[i]\n",
    "        for _, TeamA_row in df.iterrows(): \n",
    "            date = TeamA_row[\"Date\"]\n",
    "            TeamA = name\n",
    "            TeamB = clean_name(TeamA_row[\"Opponent\"])\n",
    "            Result = 1 if TeamA_row[\"Result\"][0] == 'W' else 0\n",
    "            S = TeamA_row[\"S\"]\n",
    "            TeamA_stats = TeamA_row[features]\n",
    "            try:\n",
    "                TeamB_df = dfs[team_names.index(TeamB)]\n",
    "            except:\n",
    "                err_a += 1\n",
    "                continue\n",
    "            try:\n",
    "                TeamB_row = TeamB_df[(TeamB_df[\"Date\"] == date) & TeamB_df[\"Opponent\"].str.contains(TeamA)].reset_index().loc[0]\n",
    "            except:\n",
    "                err_b += 1\n",
    "                continue\n",
    "\n",
    "            TeamB_stats = TeamB_row[features]\n",
    "            data.append([date, TeamA, TeamB, Result, S, *TeamA_stats, *TeamB_stats])\n",
    "        \n",
    "    combined_df = pd.DataFrame(data, columns=combined_features)\n",
    "    combined_df.to_csv(output_path, index=False)\n",
    "    results = dict(df_length=len(combined_df), err_a=err_a, err_b=err_b)\n",
    "    print(f\"Done! Results: {results}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "def prev_combine(input_path, output_path):\n",
    "    print(\"Combing data using cumulatives for team matches ...\", end=' ')\n",
    "    dfs = []\n",
    "    team_names = []\n",
    "    for root, _, files in os.walk(input_path):\n",
    "        for f in files:\n",
    "            team_names.append(f[:-4])\n",
    "            dfs.append(pd.read_csv(Path(root).joinpath(f)))\n",
    "\n",
    "    data = []\n",
    "\n",
    "    err_a = 0\n",
    "    err_b = 0\n",
    "\n",
    "    for i, name in enumerate(team_names):\n",
    "        df = dfs[i]\n",
    "        for j in range(len(df)):\n",
    "            if j == 0:\n",
    "                continue\n",
    "            TeamA_row = df.loc[j-1]\n",
    "            date = TeamA_row[\"Date\"]\n",
    "            TeamA = name\n",
    "            TeamB = clean_name(TeamA_row[\"Opponent\"])\n",
    "            Result = 1 if TeamA_row[\"Result\"][0] == 'W' else 0\n",
    "            S = TeamA_row[\"S\"]\n",
    "            TeamA_stats = TeamA_row[features]\n",
    "            try:\n",
    "                TeamB_df = dfs[team_names.index(TeamB)]\n",
    "            except:\n",
    "                err_a += 1\n",
    "                continue\n",
    "            try:\n",
    "                TeamB_row_index = TeamB_df[(TeamB_df[\"Date\"] == date) & TeamB_df[\"Opponent\"].str.contains(TeamA)].index[0]\n",
    "                if TeamB_row_index == 0:\n",
    "                    continue\n",
    "                TeamB_row = TeamB_df.loc[TeamB_row_index-1]\n",
    "            except:\n",
    "                err_b += 1\n",
    "                continue\n",
    "\n",
    "            TeamB_stats = TeamB_row[features]\n",
    "            data.append([date, TeamA, TeamB, Result, S, *TeamA_stats, *TeamB_stats])\n",
    "        \n",
    "    combined_df = pd.DataFrame(data, columns=combined_features)\n",
    "    combined_df.to_csv(output_path, index=False)\n",
    "    results = dict(df_length=len(combined_df), err_a=err_a, err_b=err_b)\n",
    "    print(f\"Done! Results: {results}. Data stored at {output_path}\")\n",
    "    return results"
   ]
  },
  {
   "source": [
    "## Compile all the yearwise combined data into a single dataframe with SMA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Combing data using cumulatives for team matches ... Done! Results: {'df_length': 36348, 'err_a': 2042, 'err_b': 246}. Data stored at ../../data/ncaa/combined/accumulated/10_sma_combined.csv\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'df_length': 36348, 'err_a': 2042, 'err_b': 246}"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "window = 10\n",
    "prev_combine(\n",
    "    input_path=f'../../data/ncaa/combined/game_by_game_{window}_sma_combined',\n",
    "    output_path=f'../../data/ncaa/combined/accumulated/{window}_sma_combined.csv',\n",
    ")"
   ]
  },
  {
   "source": [
    "## Compile all the yearwise combined data into a single dataframe with CMA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Combing data using cumulatives for team matches ... Done! Results: {'df_length': 36348, 'err_a': 2042, 'err_b': 246}. Data stored at ../../data/ncaa/combined/accumulated/cma_combined.csv\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'df_length': 36348, 'err_a': 2042, 'err_b': 246}"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "prev_combine(\n",
    "            input_path=f'../../data/ncaa/combined/game_by_game_cma_combined',\n",
    "            output_path=f'../../data/ncaa/combined/accumulated/cma_combined.csv',\n",
    "        )"
   ]
  },
  {
   "source": [
    "## Compile all the yearwise combined data into a single dataframe with EWM"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Combing data using cumulatives for team matches ... Done! Results: {'df_length': 36348, 'err_a': 2042, 'err_b': 246}. Data stored at ../../data/ncaa/combined/accumulated/0.2_ewm_combined.csv\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'df_length': 36348, 'err_a': 2042, 'err_b': 246}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "alpha = 0.2\n",
    "prev_combine(\n",
    "    input_path=f'../../data/ncaa/combined/game_by_game_{alpha}_ewm_combined',\n",
    "    output_path=f'../../data/ncaa/combined/accumulated/{alpha}_ewm_combined.csv',\n",
    ")"
   ]
  },
  {
   "source": [
    "# Combining Player Data (w.r.t. years)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Moving the files out of the team directory"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Marisa.csv no found for 2016\n",
      "Cornist, Kerra.csv no found for 2017\n",
      "Cornist, Kerra.csv no found for 2016\n",
      "Coates, Mackenzie.csv no found for 2016\n",
      "Brown, Madison.csv no found for 2016\n",
      "Migliore, Mia.csv no found for 2018\n",
      "Migliore, Mia.csv no found for 2017\n",
      "Migliore, Mia.csv no found for 2016\n",
      "Hamilton, Abby.csv no found for 2017\n",
      "Hamilton, Abby.csv no found for 2016\n",
      "Leblanc, Renee.csv no found for 2016\n",
      "Sisic, Isidora.csv no found for 2018\n",
      "Sisic, Isidora.csv no found for 2017\n",
      "Sisic, Isidora.csv no found for 2016\n",
      "Thomison, Ryann.csv no found for 2016\n",
      "Bramschreiber, Shanel.csv no found for 2017\n",
      "Bramschreiber, Shanel.csv no found for 2016\n",
      "Nomura, Kanile'a.csv no found for 2016\n",
      "Weiby, Sarah.csv no found for 2018\n",
      "Weiby, Sarah.csv no found for 2017\n",
      "Weiby, Sarah.csv no found for 2016\n",
      "Karlen, Miranda.csv no found for 2016\n",
      "Strobert, Briana.csv no found for 2018\n",
      "Strobert, Briana.csv no found for 2017\n",
      "Strobert, Briana.csv no found for 2016\n",
      "Wehrheim, Annie.csv no found for 2016\n",
      "Fuller, Haley.csv no found for 2016\n",
      "DeFalco, Teagan.csv no found for 2016\n",
      "Markowski, Kelly.csv no found for 2018\n",
      "Markowski, Kelly.csv no found for 2017\n",
      "Markowski, Kelly.csv no found for 2016\n",
      "Smylie, Allie.csv no found for 2018\n",
      "Smylie, Allie.csv no found for 2017\n",
      "Smylie, Allie.csv no found for 2016\n",
      "Straw, Alisha.csv no found for 2018\n",
      "Straw, Alisha.csv no found for 2017\n",
      "Straw, Alisha.csv no found for 2016\n",
      "Cardoner, Miriam.csv no found for 2018\n",
      "Cardoner, Miriam.csv no found for 2017\n",
      "Cardoner, Miriam.csv no found for 2016\n",
      "Flores, Morgan.csv no found for 2018\n",
      "Flores, Morgan.csv no found for 2017\n",
      "Flores, Morgan.csv no found for 2016\n",
      "Biassou, Kaitlynn.csv no found for 2018\n",
      "Biassou, Kaitlynn.csv no found for 2017\n",
      "Biassou, Kaitlynn.csv no found for 2016\n",
      "Moffet, Emma.csv no found for 2017\n",
      "Moffet, Emma.csv no found for 2016\n",
      "Slagle, Maddie.csv no found for 2017\n",
      "Slagle, Maddie.csv no found for 2016\n",
      "Proctor, Lindsay.csv no found for 2016\n",
      "Pamphile, Elizabeth.csv no found for 2016\n",
      "Banda, Busi.csv no found for 2017\n",
      "Banda, Busi.csv no found for 2016\n",
      "Scanlon, Karen.csv no found for 2017\n",
      "Scanlon, Karen.csv no found for 2016\n",
      "Milojevic, Tijana.csv no found for 2016\n",
      "Wehrstein, Ashley.csv no found for 2017\n",
      "Wehrstein, Ashley.csv no found for 2016\n",
      "Bath, Renata.csv no found for 2018\n",
      "Bath, Renata.csv no found for 2017\n",
      "Bath, Renata.csv no found for 2016\n",
      "Neelon, Meghan.csv no found for 2016\n",
      "Merrill, Seren.csv no found for 2016\n",
      "Morse, Rachel.csv no found for 2018\n",
      "Morse, Rachel.csv no found for 2017\n",
      "Morse, Rachel.csv no found for 2016\n",
      "Hall, Thayer.csv no found for 2017\n",
      "Hall, Thayer.csv no found for 2016\n",
      "Kells, Alex.csv no found for 2016\n",
      "Hamrick, Lexie.csv no found for 2017\n",
      "Hamrick, Lexie.csv no found for 2016\n",
      "Feighery, Celie.csv no found for 2018\n",
      "Feighery, Celie.csv no found for 2017\n",
      "Feighery, Celie.csv no found for 2016\n",
      "Ruiz, Laura.csv no found for 2018\n",
      "Ruiz, Laura.csv no found for 2017\n",
      "Ruiz, Laura.csv no found for 2016\n",
      "Scott, Nia.csv no found for 2017\n",
      "Scott, Nia.csv no found for 2016\n",
      "Harman, Haley.csv no found for 2016\n",
      "Davis, Avri.csv no found for 2018\n",
      "Davis, Avri.csv no found for 2017\n",
      "Davis, Avri.csv no found for 2016\n",
      "Cox, Ellie.csv no found for 2018\n",
      "Cox, Ellie.csv no found for 2017\n",
      "Cox, Ellie.csv no found for 2016\n",
      "Subbert, Kayla.csv no found for 2017\n",
      "Subbert, Kayla.csv no found for 2016\n",
      "Anderson, Nicole.csv no found for 2018\n",
      "Anderson, Nicole.csv no found for 2017\n",
      "Anderson, Nicole.csv no found for 2016\n",
      "McCracken, Katie.csv no found for 2018\n",
      "McCracken, Katie.csv no found for 2017\n",
      "McCracken, Katie.csv no found for 2016\n",
      "Lippert, Allison.csv no found for 2016\n",
      "Popernik, Maya.csv no found for 2017\n",
      "Popernik, Maya.csv no found for 2016\n",
      "Kirkpatrick, Mckenna.csv no found for 2016\n",
      "Fujitani, Erin.csv no found for 2018\n",
      "Fujitani, Erin.csv no found for 2017\n",
      "Fujitani, Erin.csv no found for 2016\n",
      "McGregor, Madeline.csv no found for 2018\n",
      "McGregor, Madeline.csv no found for 2017\n",
      "McGregor, Madeline.csv no found for 2016\n",
      "Hopp, Reagan.csv no found for 2018\n",
      "Hopp, Reagan.csv no found for 2017\n",
      "Hopp, Reagan.csv no found for 2016\n",
      "Jarman, Christine.csv no found for 2016\n",
      "Wilson, Reanna.csv no found for 2018\n",
      "Wilson, Reanna.csv no found for 2017\n",
      "Wilson, Reanna.csv no found for 2016\n",
      "Buchanan, Emma.csv no found for 2017\n",
      "Buchanan, Emma.csv no found for 2016\n",
      "Nayar, Alyssa.csv no found for 2018\n",
      "Nayar, Alyssa.csv no found for 2017\n",
      "Nayar, Alyssa.csv no found for 2016\n",
      "Dunn, Natalie.csv no found for 2018\n",
      "Dunn, Natalie.csv no found for 2017\n",
      "Dunn, Natalie.csv no found for 2016\n",
      "Smith, Bre.csv no found for 2018\n",
      "Smith, Bre.csv no found for 2017\n",
      "Smith, Bre.csv no found for 2016\n",
      "Gadelha, Elis.csv no found for 2016\n",
      "Kinney, Rachel.csv no found for 2017\n",
      "Kinney, Rachel.csv no found for 2016\n",
      "Slovak, Annika.csv no found for 2018\n",
      "Slovak, Annika.csv no found for 2017\n",
      "Slovak, Annika.csv no found for 2016\n",
      "Lee, Alexis.csv no found for 2017\n",
      "Santrac, Nevena.csv no found for 2017\n",
      "Santrac, Nevena.csv no found for 2016\n",
      "Carr, Johnasia.csv no found for 2018\n",
      "Carr, Johnasia.csv no found for 2017\n",
      "Carr, Johnasia.csv no found for 2016\n",
      "Perdue, Neena.csv no found for 2017\n",
      "Perdue, Neena.csv no found for 2016\n",
      "Tyson, Natalie.csv no found for 2017\n",
      "Tyson, Natalie.csv no found for 2016\n",
      "Ankrum, Brenna.csv no found for 2017\n",
      "Ankrum, Brenna.csv no found for 2016\n",
      "Bianco, Sabrina.csv no found for 2017\n",
      "Bianco, Sabrina.csv no found for 2016\n",
      "Jones, Erika.csv no found for 2018\n",
      "Jones, Erika.csv no found for 2017\n",
      "Giron, Jennifer.csv no found for 2018\n",
      "Giron, Jennifer.csv no found for 2017\n",
      "Giron, Jennifer.csv no found for 2016\n",
      "Askew, Nina.csv no found for 2017\n",
      "Askew, Nina.csv no found for 2016\n",
      "Taylor, Ryleigh.csv no found for 2017\n",
      "Taylor, Ryleigh.csv no found for 2016\n",
      "Spicer, Hannah.csv no found for 2017\n",
      "Spicer, Hannah.csv no found for 2016\n",
      "Culumovic, Katie.csv no found for 2018\n",
      "Culumovic, Katie.csv no found for 2017\n",
      "Culumovic, Katie.csv no found for 2016\n",
      "Norris, Mattie.csv no found for 2017\n",
      "Norris, Mattie.csv no found for 2016\n",
      "Fisher, Alex.csv no found for 2016\n",
      "Bustamante, Abril.csv no found for 2018\n",
      "Bustamante, Abril.csv no found for 2017\n",
      "Bustamante, Abril.csv no found for 2016\n",
      "Borges, Julia.csv no found for 2017\n",
      "Borges, Julia.csv no found for 2016\n",
      "Charitonidi, Ioanna.csv no found for 2018\n",
      "Charitonidi, Ioanna.csv no found for 2017\n",
      "Charitonidi, Ioanna.csv no found for 2016\n",
      "Pitsas, Lexi.csv no found for 2016\n",
      "Pearson, Victoria.csv no found for 2016\n",
      "Chavira, Tia.csv no found for 2018\n",
      "Chavira, Tia.csv no found for 2017\n",
      "Chavira, Tia.csv no found for 2016\n",
      "Evans, Melissa.csv no found for 2016\n",
      "Abeyta, Zoe.csv no found for 2017\n",
      "Abeyta, Zoe.csv no found for 2016\n",
      "Meyer, Nicoleta.csv no found for 2017\n",
      "Meyer, Nicoleta.csv no found for 2016\n",
      "Hernandez, Brenda.csv no found for 2018\n",
      "Hernandez, Brenda.csv no found for 2017\n",
      "Hernandez, Brenda.csv no found for 2016\n",
      "Ruble, Maddi.csv no found for 2017\n",
      "Ruble, Maddi.csv no found for 2016\n",
      "Wood, Bri.csv no found for 2016\n",
      "Jandris, Molly.csv no found for 2018\n",
      "Jandris, Molly.csv no found for 2017\n",
      "Jandris, Molly.csv no found for 2016\n",
      "Oelrich, Ashley.csv no found for 2017\n",
      "Oelrich, Ashley.csv no found for 2016\n",
      "Rosenthall, Bella.csv no found for 2017\n",
      "Rosenthall, Bella.csv no found for 2016\n",
      "McFarland, Erin.csv no found for 2017\n",
      "McFarland, Erin.csv no found for 2016\n",
      "Botkin, Brooke.csv no found for 2016\n",
      "Lowe, Maddie.csv no found for 2017\n",
      "Lowe, Maddie.csv no found for 2016\n",
      "Burt, Lauryn.csv no found for 2017\n",
      "Burt, Lauryn.csv no found for 2016\n",
      "Cozad, Grace.csv no found for 2017\n",
      "Cozad, Grace.csv no found for 2016\n",
      "Kit, Lisie.csv no found for 2016\n",
      "Hinkle, Loren.csv no found for 2018\n",
      "Hinkle, Loren.csv no found for 2017\n",
      "Hinkle, Loren.csv no found for 2016\n",
      "Mambu, Mujay.csv no found for 2018\n",
      "Mambu, Mujay.csv no found for 2017\n",
      "Mambu, Mujay.csv no found for 2016\n",
      "Donovan, Vivian.csv no found for 2017\n",
      "Donovan, Vivian.csv no found for 2016\n",
      "Allor, Ryan.csv no found for 2018\n",
      "Allor, Ryan.csv no found for 2017\n",
      "Allor, Ryan.csv no found for 2016\n",
      "Garrison, Krysten.csv no found for 2017\n",
      "Garrison, Krysten.csv no found for 2016\n",
      "Bolden, Sophia.csv no found for 2018\n",
      "Bolden, Sophia.csv no found for 2017\n",
      "Bolden, Sophia.csv no found for 2016\n",
      "Maddera, Ryan.csv no found for 2018\n",
      "Maddera, Ryan.csv no found for 2017\n",
      "Maddera, Ryan.csv no found for 2016\n",
      "Minshew, Callie.csv no found for 2018\n",
      "Minshew, Callie.csv no found for 2017\n",
      "Minshew, Callie.csv no found for 2016\n",
      "Tyler, Ars'Breana.csv no found for 2016\n",
      "Thompson, Amilya.csv no found for 2018\n",
      "Thompson, Amilya.csv no found for 2017\n",
      "Thompson, Amilya.csv no found for 2016\n",
      "Plett, Sophia.csv no found for 2016\n",
      "Matheny, Madeline.csv no found for 2018\n",
      "Matheny, Madeline.csv no found for 2017\n",
      "Matheny, Madeline.csv no found for 2016\n",
      "Bergmark, Bella.csv no found for 2017\n",
      "Bergmark, Bella.csv no found for 2016\n",
      "Johnson, Holaimoana.csv no found for 2016\n",
      "Didawick, Taylor.csv no found for 2017\n",
      "Didawick, Taylor.csv no found for 2016\n",
      "DeYoung, Kari.csv no found for 2018\n",
      "DeYoung, Kari.csv no found for 2017\n",
      "DeYoung, Kari.csv no found for 2016\n",
      "Knuth, Taryn.csv no found for 2016\n",
      "Thompson, Savannah.csv no found for 2017\n",
      "Thompson, Savannah.csv no found for 2016\n",
      "Coggin, Karagan.csv no found for 2018\n",
      "Coggin, Karagan.csv no found for 2017\n",
      "Coggin, Karagan.csv no found for 2016\n",
      "Lewis, Morgan.csv no found for 2018\n",
      "Lewis, Morgan.csv no found for 2017\n",
      "Macy, Kailey.csv no found for 2016\n",
      "Holly, Sh'Diamond.csv no found for 2018\n",
      "Holly, Sh'Diamond.csv no found for 2017\n",
      "Holly, Sh'Diamond.csv no found for 2016\n",
      "Joiner, Garrett.csv no found for 2017\n",
      "Joiner, Garrett.csv no found for 2016\n",
      "Garcia, Kathya.csv no found for 2017\n",
      "Garcia, Kathya.csv no found for 2016\n",
      "Grbac, Ella.csv no found for 2017\n",
      "Grbac, Ella.csv no found for 2016\n",
      "Wattles, Sequoia.csv no found for 2018\n",
      "Wattles, Sequoia.csv no found for 2017\n",
      "Wattles, Sequoia.csv no found for 2016\n",
      "Becker, Hannah.csv no found for 2016\n",
      "Dimas, Neena.csv no found for 2017\n",
      "Dimas, Neena.csv no found for 2016\n",
      "Malinowski, Abbey.csv no found for 2017\n",
      "Malinowski, Abbey.csv no found for 2016\n",
      "Seehase, Jaydlin.csv no found for 2016\n",
      "Cooper, Kara.csv no found for 2018\n",
      "Cooper, Kara.csv no found for 2017\n",
      "Cooper, Kara.csv no found for 2016\n",
      "Montag, Amanda.csv no found for 2016\n",
      "Overmyer, Hannah.csv no found for 2017\n",
      "Overmyer, Hannah.csv no found for 2016\n",
      "Pajevic, Sophie.csv no found for 2018\n",
      "Pajevic, Sophie.csv no found for 2017\n",
      "Pajevic, Sophie.csv no found for 2016\n",
      "Nagle, Jenna.csv no found for 2016\n",
      "Makonova, Hana.csv no found for 2017\n",
      "Makonova, Hana.csv no found for 2016\n",
      "Perry, Savannah.csv no found for 2018\n",
      "Perry, Savannah.csv no found for 2017\n",
      "Perry, Savannah.csv no found for 2016\n",
      "Lane, Colby.csv no found for 2018\n",
      "Lane, Colby.csv no found for 2017\n",
      "Lane, Colby.csv no found for 2016\n",
      "Hodges, Ajani.csv no found for 2018\n",
      "Hodges, Ajani.csv no found for 2017\n",
      "Hodges, Ajani.csv no found for 2016\n",
      "Morgan, Brigham.csv no found for 2018\n",
      "Morgan, Brigham.csv no found for 2017\n",
      "Morgan, Brigham.csv no found for 2016\n",
      "Gergen, Gillian.csv no found for 2016\n",
      "Murphy, Ally.csv no found for 2017\n",
      "Murphy, Ally.csv no found for 2016\n",
      "Shacoski, Gabrielle.csv no found for 2017\n",
      "Shacoski, Gabrielle.csv no found for 2016\n",
      "Sands, BreyAnn.csv no found for 2018\n",
      "Sands, BreyAnn.csv no found for 2017\n",
      "Sands, BreyAnn.csv no found for 2016\n",
      "Carpenter, Tori.csv no found for 2018\n",
      "Carpenter, Tori.csv no found for 2017\n",
      "Carpenter, Tori.csv no found for 2016\n",
      "Deloney, Alyssa.csv no found for 2016\n",
      "Willison, Abbey.csv no found for 2018\n",
      "Willison, Abbey.csv no found for 2016\n",
      "King, Grace.csv no found for 2018\n",
      "King, Grace.csv no found for 2017\n",
      "King, Grace.csv no found for 2016\n",
      "Der, Stephanie.csv no found for 2018\n",
      "Der, Stephanie.csv no found for 2017\n",
      "Der, Stephanie.csv no found for 2016\n",
      "Slavik, McKenna.csv no found for 2018\n",
      "Slavik, McKenna.csv no found for 2017\n",
      "Slavik, McKenna.csv no found for 2016\n",
      "Massey, Grace.csv no found for 2016\n",
      "Ell, Annie.csv no found for 2016\n",
      "Blake, Susan.csv no found for 2018\n",
      "Blake, Susan.csv no found for 2017\n",
      "Blake, Susan.csv no found for 2016\n",
      "Bulatovic, Jovana.csv no found for 2016\n",
      "Bennett, Rachael.csv no found for 2018\n",
      "Bennett, Rachael.csv no found for 2017\n",
      "Bennett, Rachael.csv no found for 2016\n",
      "Miranda, DeBeary.csv no found for 2018\n",
      "Miranda, DeBeary.csv no found for 2017\n",
      "Miranda, DeBeary.csv no found for 2016\n",
      "Kramer, Rachael.csv no found for 2017\n",
      "Bradford, Carissa.csv no found for 2018\n",
      "Bradford, Carissa.csv no found for 2017\n",
      "Bradford, Carissa.csv no found for 2016\n",
      "McClure, Malie.csv no found for 2018\n",
      "McClure, Malie.csv no found for 2017\n",
      "McClure, Malie.csv no found for 2016\n",
      "Rastelli, Rachele.csv no found for 2017\n",
      "Rastelli, Rachele.csv no found for 2016\n",
      "Cummings, Ally.csv no found for 2016\n",
      "Downs, Kaili.csv no found for 2017\n",
      "Downs, Kaili.csv no found for 2016\n",
      "Freeman, Morgan.csv no found for 2017\n",
      "Freeman, Morgan.csv no found for 2016\n",
      "Gross, Elyse.csv no found for 2018\n",
      "Gross, Elyse.csv no found for 2017\n",
      "Gross, Elyse.csv no found for 2016\n",
      "Gormally, Shannon.csv no found for 2018\n",
      "Gormally, Shannon.csv no found for 2017\n",
      "Gormally, Shannon.csv no found for 2016\n",
      "Ratzlaff, Alex.csv no found for 2016\n",
      "Andrews, Sydney.csv no found for 2017\n",
      "Andrews, Sydney.csv no found for 2016\n",
      "Wilson, Megan.csv no found for 2016\n",
      "Martin, Shelby.csv no found for 2016\n",
      "Huser, Abigail.csv no found for 2016\n",
      "Boyer, Joslyn.csv no found for 2018\n",
      "Boyer, Joslyn.csv no found for 2017\n",
      "Boyer, Joslyn.csv no found for 2016\n",
      "Fitzmorris, Audriana.csv no found for 2018\n",
      "Watkins, Kelsey.csv no found for 2018\n",
      "Watkins, Kelsey.csv no found for 2017\n",
      "Watkins, Kelsey.csv no found for 2016\n",
      "Mongan, Kailynn.csv no found for 2016\n",
      "Gillingham, Brittany.csv no found for 2016\n",
      "VanSeveren, Emma.csv no found for 2018\n",
      "VanSeveren, Emma.csv no found for 2017\n",
      "VanSeveren, Emma.csv no found for 2016\n",
      "Tastad, Camryn.csv no found for 2017\n",
      "Tastad, Camryn.csv no found for 2016\n",
      "Ganley, Gabi.csv no found for 2018\n",
      "Ganley, Gabi.csv no found for 2017\n",
      "Ganley, Gabi.csv no found for 2016\n",
      "Hess, Rachel.csv no found for 2018\n",
      "Hess, Rachel.csv no found for 2017\n",
      "Hess, Rachel.csv no found for 2016\n",
      "Shields, Madison.csv no found for 2017\n",
      "Shields, Madison.csv no found for 2016\n",
      "Kirby, Alex.csv no found for 2017\n",
      "Kirby, Alex.csv no found for 2016\n",
      "Sprinkle, Abbey.csv no found for 2016\n",
      "Adekunle, Anota.csv no found for 2017\n",
      "Adekunle, Anota.csv no found for 2016\n",
      "Dominique, Simone.csv no found for 2018\n",
      "Dominique, Simone.csv no found for 2017\n",
      "Dominique, Simone.csv no found for 2016\n",
      "Pertofsky, May.csv no found for 2018\n",
      "Pertofsky, May.csv no found for 2017\n",
      "Pertofsky, May.csv no found for 2016\n",
      "Capllonch, Shelby.csv no found for 2018\n",
      "Capllonch, Shelby.csv no found for 2017\n",
      "Capllonch, Shelby.csv no found for 2016\n",
      "Walker, Andrea.csv no found for 2016\n",
      "Renn, Maddie.csv no found for 2017\n",
      "Renn, Maddie.csv no found for 2016\n",
      "Papesh, Alli.csv no found for 2017\n",
      "Papesh, Alli.csv no found for 2016\n",
      "Keefe, Michaela.csv no found for 2018\n",
      "Fuller, Elana.csv no found for 2018\n",
      "Fuller, Elana.csv no found for 2017\n",
      "Fuller, Elana.csv no found for 2016\n",
      "LIVINGSTON, Atley.csv no found for 2018\n",
      "LIVINGSTON, Atley.csv no found for 2017\n",
      "LIVINGSTON, Atley.csv no found for 2016\n",
      "Ryan, Maggie.csv no found for 2018\n",
      "Ryan, Maggie.csv no found for 2017\n",
      "Ryan, Maggie.csv no found for 2016\n",
      "Francis, Jayna.csv no found for 2018\n",
      "Francis, Jayna.csv no found for 2017\n",
      "Francis, Jayna.csv no found for 2016\n",
      "Lowes, Emma.csv no found for 2018\n",
      "Lowes, Emma.csv no found for 2017\n",
      "Lowes, Emma.csv no found for 2016\n",
      "Muhammad, Nahla.csv no found for 2018\n",
      "Muhammad, Nahla.csv no found for 2017\n",
      "Muhammad, Nahla.csv no found for 2016\n",
      "Ward, Madelyn.csv no found for 2016\n",
      "Pua'a, Emi.csv no found for 2017\n",
      "Pua'a, Emi.csv no found for 2016\n",
      "Sheridan, Savannah.csv no found for 2018\n",
      "Sheridan, Savannah.csv no found for 2017\n",
      "Sheridan, Savannah.csv no found for 2016\n",
      "Yim, Malia.csv no found for 2018\n",
      "Yim, Malia.csv no found for 2017\n",
      "Yim, Malia.csv no found for 2016\n",
      "Pitt, Courteney.csv no found for 2016\n",
      "Akinwumi, Tola.csv no found for 2016\n",
      "Lund, Nicole.csv no found for 2018\n",
      "Lund, Nicole.csv no found for 2017\n",
      "Lund, Nicole.csv no found for 2016\n",
      "Buckley, Taylor.csv no found for 2018\n",
      "Buckley, Taylor.csv no found for 2017\n",
      "Buckley, Taylor.csv no found for 2016\n",
      "Kocabiyik, Aybuke.csv no found for 2016\n",
      "Reeb, Maddy.csv no found for 2016\n",
      "Smith, Kincey.csv no found for 2016\n",
      "Murray, Gabby.csv no found for 2018\n",
      "Murray, Gabby.csv no found for 2017\n",
      "Murray, Gabby.csv no found for 2016\n",
      "Miller, Madelynn.csv no found for 2016\n",
      "Slaughter, Sami.csv no found for 2016\n",
      "Pence, Emma.csv no found for 2018\n",
      "Pence, Emma.csv no found for 2017\n",
      "Pence, Emma.csv no found for 2016\n",
      "Hames, Nicklin.csv no found for 2017\n",
      "Hames, Nicklin.csv no found for 2016\n",
      "Lawson-Body, Samira.csv no found for 2017\n",
      "Lawson-Body, Samira.csv no found for 2016\n",
      "Khouri, Helena.csv no found for 2017\n",
      "Khouri, Helena.csv no found for 2016\n",
      "Belles, Emersen.csv no found for 2018\n",
      "Belles, Emersen.csv no found for 2017\n",
      "Belles, Emersen.csv no found for 2016\n",
      "Biegelmeyer, Rafaela.csv no found for 2018\n",
      "Biegelmeyer, Rafaela.csv no found for 2017\n",
      "Biegelmeyer, Rafaela.csv no found for 2016\n",
      "Karakasi, Elena.csv no found for 2017\n",
      "Karakasi, Elena.csv no found for 2016\n",
      "Paalman, Tiffany.csv no found for 2018\n",
      "Paalman, Tiffany.csv no found for 2017\n",
      "Paalman, Tiffany.csv no found for 2016\n",
      "Smevog, Sarah.csv no found for 2017\n",
      "Smevog, Sarah.csv no found for 2016\n",
      "Grant, Jillie.csv no found for 2017\n",
      "Grant, Jillie.csv no found for 2016\n",
      "Sellers, Kristin.csv no found for 2017\n",
      "Sellers, Kristin.csv no found for 2016\n",
      "Acchione, Alaina.csv no found for 2016\n",
      "Creery, Mason.csv no found for 2018\n",
      "Creery, Mason.csv no found for 2017\n",
      "Creery, Mason.csv no found for 2016\n",
      "Riedl, Jessica.csv no found for 2017\n",
      "Riedl, Jessica.csv no found for 2016\n",
      "Cohen, Jessie.csv no found for 2017\n",
      "Cohen, Jessie.csv no found for 2016\n",
      "Souza, Brianna.csv no found for 2017\n",
      "Souza, Brianna.csv no found for 2016\n",
      "Eske, Alyssa.csv no found for 2018\n",
      "Eske, Alyssa.csv no found for 2017\n",
      "Eske, Alyssa.csv no found for 2016\n",
      "Osborn, Elizabeth.csv no found for 2017\n",
      "Osborn, Elizabeth.csv no found for 2016\n",
      "Moore, Brooke.csv no found for 2016\n",
      "Dernehl, Allyson.csv no found for 2017\n",
      "Dernehl, Allyson.csv no found for 2016\n",
      "Jaeger, Paige.csv no found for 2017\n",
      "Jaeger, Paige.csv no found for 2016\n",
      "Janok, Lauren.csv no found for 2017\n",
      "Janok, Lauren.csv no found for 2016\n",
      "Wagstaff, Katie.csv no found for 2017\n",
      "Wagstaff, Katie.csv no found for 2016\n",
      "Vukcevic, Jovana.csv no found for 2018\n",
      "Vukcevic, Jovana.csv no found for 2017\n",
      "Vukcevic, Jovana.csv no found for 2016\n",
      "Napierala, Mandy.csv no found for 2017\n",
      "White, Payton.csv no found for 2016\n",
      "Conner, Camille.csv no found for 2016\n",
      "Finnerty, Lexy.csv no found for 2018\n",
      "Finnerty, Lexy.csv no found for 2017\n",
      "Finnerty, Lexy.csv no found for 2016\n",
      "Bentley, Holly.csv no found for 2018\n",
      "Bentley, Holly.csv no found for 2017\n",
      "Bentley, Holly.csv no found for 2016\n",
      "Jake-Turner, Kennadie.csv no found for 2017\n",
      "Jake-Turner, Kennadie.csv no found for 2016\n",
      "Missroon, Sarah.csv no found for 2018\n",
      "Missroon, Sarah.csv no found for 2017\n",
      "Missroon, Sarah.csv no found for 2016\n",
      "Gonzlez, Ashley.csv no found for 2018\n",
      "Gonzlez, Ashley.csv no found for 2017\n",
      "Gonzlez, Ashley.csv no found for 2016\n",
      "Johnson, Rachael.csv no found for 2017\n",
      "Johnson, Rachael.csv no found for 2016\n",
      "Osborne, Adjuwa.csv no found for 2016\n",
      "Hoener, Erin.csv no found for 2016\n",
      "Green, Kathryn.csv no found for 2016\n",
      "Chamulak, Callie.csv no found for 2017\n",
      "Chamulak, Callie.csv no found for 2016\n",
      "Jansen, Rhea.csv no found for 2018\n",
      "Jansen, Rhea.csv no found for 2017\n",
      "Jansen, Rhea.csv no found for 2016\n",
      "Shoopman, Laura.csv no found for 2018\n",
      "Shoopman, Laura.csv no found for 2017\n",
      "Shoopman, Laura.csv no found for 2016\n",
      "Tilly, Peyton.csv no found for 2018\n",
      "Tilly, Peyton.csv no found for 2017\n",
      "Tilly, Peyton.csv no found for 2016\n",
      "Houghton, Sianna.csv no found for 2018\n",
      "Houghton, Sianna.csv no found for 2017\n",
      "Houghton, Sianna.csv no found for 2016\n",
      "Schwan, Mckenzie.csv no found for 2016\n",
      "DePersio, Gabby.csv no found for 2018\n",
      "DePersio, Gabby.csv no found for 2017\n",
      "DePersio, Gabby.csv no found for 2016\n",
      "Buddy, Parker.csv no found for 2017\n",
      "Buddy, Parker.csv no found for 2016\n",
      "Spevak, Kaila.csv no found for 2017\n",
      "Spevak, Kaila.csv no found for 2016\n",
      "Tedesco, Danielle.csv no found for 2016\n",
      "McNally, Madison.csv no found for 2017\n",
      "McNally, Madison.csv no found for 2016\n",
      "Stamatiou, Chrysanthi.csv no found for 2016\n"
     ]
    }
   ],
   "source": [
    "years = [2019, 2018, 2017, 2016]\n",
    "root_path = Path(f\"../../data/ncaa/processed/\")\n",
    "failed_list = []\n",
    "for year in years:\n",
    "    for _, dirs, files in os.walk(f\"../../data/ncaa/processed/{year}/player_game_wise_cleaned\"):\n",
    "        outpath = Path(f\"../../data/ncaa/combined/{year}/player_game_wise_cleaned\")\n",
    "        outpath.mkdir(parents=True, exist_ok=True)\n",
    "        for d in dirs:\n",
    "            for sub_root, _, sub_files in os.walk(root_path.joinpath(f\"{year}/player_game_wise_cleaned/{d}\")):\n",
    "                for f in sub_files:\n",
    "                    print(f\"Copying {sub_root}/{f}\")\n",
    "                    f_path = f\"{sub_root}/{f}\"\n",
    "                    shutil.copy(f_path, outpath.joinpath(f\"{f}\"))\n",
    "\n",
    "final_outpath = Path(f\"../../data/ncaa/combined/player_game_wise_cleaned_combined\")\n",
    "final_outpath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "file_dir = \"../../data/ncaa/combined/2019\"\n",
    "not_found_log = []\n",
    "for _, _, files in os.walk(file_dir):\n",
    "    for f in files:\n",
    "        df_list = []\n",
    "        for year in years:\n",
    "            try:\n",
    "                df1 = pd.read_csv(Path(file_dir).parent.joinpath(f\"{year}/player_game_wise_cleaned/{f}\"))\n",
    "                df_list.append(df1)\n",
    "            except:\n",
    "                error = f\"{f} not found for {year}\"\n",
    "                not_found_log.append(error)\n",
    "        final_df = pd.concat(df_list, ignore_index=True)\n",
    "        final_df.to_csv(final_outpath.joinpath(f\"{f}\"), index=False)\n",
    "print(\"\\n\")        \n",
    "for error in not_found_log:\n",
    "    print(error)\n",
    "        \n",
    "for year in years:\n",
    "    path = Path(file_dir).parent.joinpath(f\"{year}/player_game_wise_cleaned\")\n",
    "    shutil.rmtree(path)\n",
    "    os.rmdir(path)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_combined_player_data(input_dir, output_dir, tf):\n",
    "    for root, _, player_files in os.walk(input_dir):\n",
    "        for player_file in player_files:\n",
    "            df = pd.read_csv(Path(root).joinpath(player_file))\n",
    "            outpath = Path(output_dir)\n",
    "            tf(df)\n",
    "            outpath.mkdir(parents=True, exist_ok=True)\n",
    "            df.to_csv(outpath.joinpath(player_file), index=False)\n",
    "\n",
    "features = [\"Kills\", \"Errors\", \"Total Attacks\", \"Hit Pct\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\", \"PTS\"]"
   ]
  },
  {
   "source": [
    "## SMA on the combined player data\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 10\n",
    "\n",
    "def sma(df):\n",
    "    df[features] = df[features].rolling(window, min_periods=1).mean()\n",
    "\n",
    "\n",
    "transform_combined_player_data(\n",
    "    input_dir=f'../../data/ncaa/combined/player_game_wise_cleaned_combined/',\n",
    "    output_dir=f'../../data/ncaa/combined/player_game_wise_{window}_sma_combined/',\n",
    "    tf=sma\n",
    ")"
   ]
  },
  {
   "source": [
    "## CMA on the combined player data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cma(df):\n",
    "    df[features] = df[features].expanding().mean()\n",
    "\n",
    "transform_combined_player_data(\n",
    "    input_dir=f'../../data/ncaa/combined/player_game_wise_cleaned_combined/',\n",
    "    output_dir=f'../../data/ncaa/combined/player_game_wise_cma_combined/',\n",
    "    tf=cma\n",
    ")"
   ]
  },
  {
   "source": [
    "## EWM on the combined player data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "\n",
    "def ewm(df):\n",
    "    df[features] = df[features].ewm(alpha=alpha).mean()\n",
    "\n",
    "transform_combined_player_data(\n",
    "    input_dir=f'../../data/ncaa/combined/player_game_wise_cleaned_combined/',\n",
    "    output_dir=f'../../data/ncaa/combined/player_game_wise_{alpha}_ewm_combined/',\n",
    "    tf=ewm\n",
    ")"
   ]
  },
  {
   "source": [
    "## Making common data frame out of the combined team and player data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_name(name):\n",
    "    if '@' in name:\n",
    "        if name.index('@') == 0:\n",
    "            return name[2:]\n",
    "        else:\n",
    "            return name[:name.index('@')-1]\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "features = [\"Kills\", \"Errors\", \"Total Attacks\", \"Hit Pct\", \"Assists\", \"Aces\", \"SErr\", \"Digs\", \"RErr\", \"Block Solos\", \"Block Assists\", \"BErr\", \"PTS\"]\n",
    "player_features = [f\"Player {j} {f}\" for f in features for j in range(12)]\n",
    "combined_features = [\n",
    "\"Date\", \"TeamA\", \"TeamB\", \"Result\", \"S\", \"Team A Kills\", \"Team A Errors\", \"Team A Total Attacks\", \"Team A Hit Pct\", \"Team A Assists\", \"Team A Aces\", \"Team A SErr\", \"Team A Digs\",  \"Team A RErr\", \"Team A Block Solos\", \"Team A Block Assists\", \"Team A BErr\", \"Team A PTS\", \"Team B Kills\", \"Team B Errors\", \"Team B Total Attacks\", \"Team B Hit Pct\", \"Team B Assists\", \"Team B Aces\", \"Team B SErr\", \"Team B Digs\", \"Team B RErr\", \"Team B Block Solos\", \"Team B Block Assists\", \"Team B BErr\", \"Team B PTS\",\n",
    "*[f\"Team A {s}\" for s in player_features],\n",
    "*[f\"Team B {s}\" for s in player_features]\n",
    "]\n",
    "\n",
    "def combine_with_player(player_input_path, team_stats_paths, team_matches_path, macthes_with_player_info_path, combined_output_path):\n",
    "    print(f\"Combining player data for individual teams into {combined_output_path} -\")\n",
    "\n",
    "    print(\"\\tBuilding team index ...\", end=' ')\n",
    "    team_names = []\n",
    "    for root, _, files in os.walk(team_matches_path):\n",
    "        for f in files:\n",
    "            team_names.append(f[:-4])\n",
    "    print(\"Done!\")\n",
    "    print(team_names)\n",
    "\n",
    "    player_input_path = Path(player_input_path)\n",
    "    team_stats_paths = [Path(team_stats_path) for team_stats_path in team_stats_paths]\n",
    "    team_matches_path = Path(team_matches_path)\n",
    "    macthes_with_player_info_path = Path(macthes_with_player_info_path)\n",
    "    macthes_with_player_info_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    print(\"\\tSorting team data ...\", end=' ')\n",
    "    for i, name in enumerate(team_names):\n",
    "        if name == \"LIU\":\n",
    "            alternate_name = \"LIU Brooklyn\"\n",
    "        elif name == \"Coastal Carolina\":\n",
    "            alternate_name = \"Coastal Caro.\"\n",
    "        else:\n",
    "            alternate_name = name\n",
    "\n",
    "        team_matches_df = pd.read_csv(team_matches_path.joinpath(f\"{name}.csv\"))\n",
    "        team_matches_df['Date']= team_matches_df['Date'].map(str)\n",
    "        team_stats_dfs = []\n",
    "        for i, team_stats_path in enumerate(team_stats_paths):\n",
    "            if i == 1 or i == 2:\n",
    "                df_read = pd.read_csv(team_stats_path.joinpath(f\"{alternate_name}.csv\"))\n",
    "                team_stats_dfs.append(df_read)\n",
    "            else:\n",
    "                df_read = pd.read_csv(team_stats_path.joinpath(f\"{name}.csv\"))\n",
    "                team_stats_dfs.append(df_read)\n",
    "                \n",
    "        top_player_names_list = []\n",
    "        for team_stats_df in team_stats_dfs:\n",
    "            top_player_names = []\n",
    "            for j, (_, player_row) in enumerate(team_stats_df[(team_stats_df[\"Player\"] != \"TEAM\") & (team_stats_df[\"Player\"] != \"Totals\") & (team_stats_df.Player != \"Opponent Totals\")].sort_values(by=[\"GP\"], ascending=False).iterrows()):\n",
    "                top_player_names.append(player_row[\"Player\"])\n",
    "                if j == 11:\n",
    "                    top_player_names_list.append(top_player_names)\n",
    "                    break\n",
    "            if len(top_player_names) < 12:\n",
    "                print(f\"Could not get enough players for {name}!\")\n",
    "                continue\n",
    "\n",
    "        for j, (player_2019, player_2018, player_2017, player_2016) in enumerate(zip(*top_player_names_list)):\n",
    "            try:\n",
    "                team_matches_df_2019 = team_matches_df[team_matches_df.Date.str.contains('2019', case=False)]\n",
    "                team_matches_df_2019[[f\"Player {j} {f}\" for f in features]] = pd.read_csv(player_input_path.joinpath(f\"{player_2019}.csv\"))[features]\n",
    "            except:\n",
    "                print(f\"\\nFailed to get player {player_2019}!\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                team_matches_df_2018 = team_matches_df[team_matches_df.Date.str.contains('2018', case=False)]\n",
    "                team_matches_df_2018[[f\"Player {j} {f}\" for f in features]] = pd.read_csv(player_input_path.joinpath(f\"{player_2018}.csv\"))[features]\n",
    "            except:\n",
    "                print(f\"\\nFailed to get player {player_2018}!\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                team_matches_df_2017 = team_matches_df[team_matches_df.Date.str.contains('2017', case=False)]\n",
    "                team_matches_df_2017[[f\"Player {j} {f}\" for f in features]] = pd.read_csv(player_input_path.joinpath(f\"{player_2017}.csv\"))[features]\n",
    "            except:\n",
    "                print(f\"\\nFailed to get player {player_2017}!\")\n",
    "                continue \n",
    "\n",
    "            try:\n",
    "                team_matches_df_2016 = team_matches_df[team_matches_df.Date.str.contains('2016', case=False)]\n",
    "                team_matches_df_2016[[f\"Player {j} {f}\" for f in features]] = pd.read_csv(player_input_path.joinpath(f\"{player_2016}.csv\"))[features]\n",
    "            except:\n",
    "                print(f\"\\nFailed to get player {player_2016}!\")\n",
    "                continue\n",
    "\n",
    "            team_matches_df_list = [team_matches_df_2019, team_matches_df_2018, team_matches_df_2017, team_matches_df_2016]\n",
    "            team_matches_df = pd.concat(team_matches_df_list, ignore_index=True)\n",
    "\n",
    "        team_matches_df.to_csv(macthes_with_player_info_path.joinpath(f\"{name}.csv\"), index=False)        \n",
    "\n",
    "    print(\"Done!\")\n",
    "\n",
    "    print(\"\\tGetting match wise dataframes ...\", end=' ')\n",
    "    dfs = []\n",
    "    team_names = []\n",
    "    for root, _, files in os.walk(macthes_with_player_info_path):\n",
    "        for f in files:\n",
    "            team_names.append(f[:-4])\n",
    "            dfs.append(pd.read_csv(Path(root).joinpath(f)))\n",
    "    print(f\"Collected {len(dfs)} dataframes. Done!\")\n",
    "\n",
    "    err_a, err_b = 0, 0\n",
    "    data = []\n",
    "    print(\"\\tCombining into a single df ...\", end=' ')\n",
    "    for i in range(len(dfs)):\n",
    "        name = team_names[i]\n",
    "        df = dfs[i]\n",
    "        for j in range(len(df)):\n",
    "            if j == 0:\n",
    "                continue\n",
    "            TeamA_row = df.loc[j-1]\n",
    "            date = TeamA_row[\"Date\"]\n",
    "            TeamA = name\n",
    "            TeamB = clean_name(TeamA_row[\"Opponent\"])\n",
    "            Result = 1 if TeamA_row[\"Result\"][0] == 'W' else 0\n",
    "            S = TeamA_row[\"S\"]\n",
    "            TeamA_stats = TeamA_row[features + player_features]\n",
    "            try:\n",
    "                TeamB_df = dfs[team_names.index(TeamB)]\n",
    "            except:\n",
    "                err_a += 1\n",
    "                continue\n",
    "            try:\n",
    "                TeamB_row_index = TeamB_df[(TeamB_df[\"Date\"] == date) & TeamB_df[\"Opponent\"].str.contains(TeamA)].index[0]\n",
    "                if TeamB_row_index == 0:\n",
    "                    continue\n",
    "                TeamB_row = TeamB_df.loc[TeamB_row_index-1]\n",
    "            except:\n",
    "                err_b += 1\n",
    "                continue\n",
    "\n",
    "            TeamB_stats = TeamB_row[features + player_features]\n",
    "            data.append([date, TeamA, TeamB, Result, S, *TeamA_stats, *TeamB_stats])\n",
    "\n",
    "    combined_df = pd.DataFrame(data, columns=combined_features)\n",
    "    combined_df.to_csv(combined_output_path, index=False)\n",
    "    results = dict(df_len=len(combined_df), err_a=err_a, err_b=err_b)\n",
    "    print(f\"Done! Results = {results}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../../data/ncaa\")\n",
    "years = [2019, 2018, 2017, 2016]\n",
    "team_stats_paths = [data_path.joinpath(f\"raw/{year}/team_stats\") for year in years]"
   ]
  },
  {
   "source": [
    "## Player + Team Combined SMA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Combining player data for individual teams into ../../data/ncaa/combined/accumulated/10_sme_with_players_combined.csv -\n",
      "\tBuilding team index ... Done!\n",
      "['USC Upstate', 'Clemson', 'North Dakota', 'Army West Point', 'SIUE', 'Indiana', 'Arkansas St.', 'Arizona', 'Little Rock', 'Campbell', 'UTSA', 'Rhode Island', 'Saint Louis', 'Cincinnati', 'Lehigh', 'Winthrop', 'Nicholls St.', 'William & Mary', 'McNeese', 'N.C. A&T', 'Duquesne', 'Wisconsin', 'Temple', 'LIU', 'Eastern Mich.', 'Penn St.', 'Iowa St.', 'Central Conn. St.', 'Tennessee', 'Robert Morris', 'N.C. Central', 'FGCU', 'Jacksonville St.', 'SMU', 'Murray St.', 'Butler', 'Western Ill.', 'UC Davis', 'Seattle U', 'Montana', 'Oral Roberts', 'Syracuse', 'Valparaiso', 'Col. of Charleston', 'Michigan', 'SFA', 'Mercer', 'Missouri St.', 'Northwestern', 'Florida St.', 'Ole Miss', 'LSU', 'UMBC', 'Hofstra', 'Hawaii', 'Virginia', 'Alabama A&M', 'Kansas St.', 'Milwaukee', 'Northeastern', 'The Citadel', 'Kentucky', 'Boise St.', 'Marquette', 'NC State', 'Bradley', 'Bowling Green', 'California', 'UNLV', 'Utah Valley', 'Wichita St.', 'New Orleans', \"Saint Mary's\", 'Washington', 'Houston', 'Montana St.', 'West Virginia', 'Middle Tenn.', 'Rutgers', 'Weber St.', 'Appalachian St.', 'Santa Clara', 'Eastern Ill.', 'Texas', 'Western Mich.', 'Ohio St.', 'Cornell', 'UCLA', 'NJIT', 'Colorado', 'La.-Monroe', 'Florida', 'Jacksonville', 'Xavier', 'Alcorn', 'UTEP', 'Alabama St.', 'UT Arlington', 'Creighton', 'Cal Poly', 'Akron', 'Columbia', 'Rice', 'Central Ark.', 'Portland', 'Nevada', 'UAB', 'Bethune-Cookman', 'Wofford', 'Sacramento St.', 'Norfolk St.', 'Coastal Carolina', 'Prairie View', 'Georgetown', 'UNCW', 'Charlotte', 'Austin Peay', 'UCF', 'Bryant', 'UIC', 'Cleveland St.', 'Dayton', 'Troy', 'Howard', 'CSU Bakersfield', 'Pittsburgh', 'Kent St.', 'Iowa', 'Western Ky.', 'Southern Ill.', 'Illinois St.', 'South Alabama', 'Southern California', 'Virginia Tech', 'Tennessee St.', 'Lamar University', 'Long Beach St.', 'Presbyterian', 'Fairleigh Dickinson', 'South Fla.', 'George Mason', 'Furman', 'Auburn', 'Southern Utah', 'Stetson', 'Purdue', 'Fairfield', 'Western Caro.', 'Gardner-Webb', 'UTRGV', 'Green Bay', 'San Jose St.', 'Hartford', 'Lipscomb', 'Wright St.', 'Denver', 'Ball St.', 'Towson', 'Southern U.', 'UConn', 'Northern Colo.', 'Portland St.', 'Northwestern St.', 'Stony Brook', 'Miami', 'Albany', 'Pepperdine', 'James Madison', 'Texas Southern', 'A&M-Corpus Christi', 'Texas Tech', 'BYU', 'Yale', 'Holy Cross', 'Jackson St.', 'Minnesota', 'San Diego St.', 'Maryland', 'UC Irvine', 'Louisville', 'Purdue Fort Wayne', 'Loyola Chicago', 'FIU', 'Toledo', 'South Carolina', 'Princeton', 'High Point', 'Mississippi Val.', 'North Florida', 'Utah', 'Belmont', 'Georgia St.', 'Texas A&M', 'Radford', 'ETSU', 'Manhattan', 'Youngstown St.', 'Chicago St.', 'Air Force', 'Providence', 'South Dakota St.', 'Central Mich.', 'Loyola Maryland', \"St. John's\", 'Kansas', 'Charleston So.', 'North Dakota St.', 'VCU', 'Louisiana', 'Morgan St.', 'TCU', 'Harvard', 'Wake Forest', 'Lafayette', 'Louisiana Tech', 'Ohio', 'Dartmouth', 'Hampton', 'Wyoming', 'New Mexico St.', 'Fresno St.', 'Houston Baptist', 'Buffalo', 'Drake', 'Penn', 'Canisius', 'Florida A&M', 'Villanova', 'Duke', 'Marshall', 'Tennessee Tech', 'Quinnipiac', 'Southern Miss.', 'Baylor', 'DePaul', 'Pacific', 'La Salle', 'Marist', 'Texas St.', 'Arkansas', 'Delaware St.', 'Northern Ariz.', 'Ga. Southern', 'Eastern Ky.', 'North Carolina', 'Northern Ill.', 'Mississippi St.', 'Delaware', 'Morehead St.', 'Southeast Mo. St.', 'Navy', 'Memphis', 'Indiana St.', 'San Diego', 'Tulsa', 'UMES', 'Oregon St.', 'Gonzaga', 'Omaha', 'UT Martin', 'Grambling', 'South Dakota', 'Coppin St.', 'CSUN', 'Seton Hall', 'Notre Dame', 'Alabama', 'Rider', 'Michigan St.', 'Missouri', 'Colgate', 'Stanford', 'Fordham', 'Niagara', 'Boston College', 'Samford', 'American', 'Ark.-Pine Bluff', 'Davidson', 'East Carolina', 'Siena', 'UNI', 'Idaho St.', 'Nebraska', 'Tulane', 'Bucknell', 'UC Riverside', 'North Texas', 'Arizona St.', 'UNC Asheville', 'Southeastern La.', 'Cal St. Fullerton', 'Evansville', 'George Washington', 'San Francisco', 'New Mexico', 'Kennesaw St.', 'Binghamton', 'Saint Francis', 'Sacred Heart', 'Georgia', 'Washington St.', 'Oakland', 'Utah St.', 'UC Santa Barbara', 'Eastern Wash.', 'IUPUI', 'Sam Houston St.', 'Oregon', 'New Hampshire', 'Georgia Tech', 'Illinois', 'Oklahoma', 'Iona', 'Chattanooga', 'Brown', 'Liberty', 'UNC Greensboro', 'Northern Ky.', 'Idaho', 'St. Francis Brooklyn', 'Colorado St.', 'Fla. Atlantic', 'Elon']\n",
      "\tSorting team data ... \n",
      "Failed to get player Yeargin, Callie!\n",
      "\n",
      "Failed to get player Phillips, Lauren!\n",
      "\n",
      "Failed to get player Shearer, Rebecca!\n",
      "\n",
      "Failed to get player Tellschow, Brianna!\n",
      "\n",
      "Failed to get player Yeargin, Callie!\n",
      "\n",
      "Failed to get player Arnold, Dominique!\n",
      "\n",
      "Failed to get player Duncan, Payton!\n",
      "\n",
      "Failed to get player Yeargin, Callie!\n",
      "\n",
      "Failed to get player Haake, Madison!\n",
      "\n",
      "Failed to get player Deaville, Morgan!\n",
      "\n",
      "Failed to get player Haake, Madison!\n",
      "\n",
      "Failed to get player Shearer, Rebecca!\n",
      "\n",
      "Failed to get player Harvell, Kailey!\n",
      "\n",
      "Failed to get player Hayes, Keely!\n",
      "\n",
      "Failed to get player Gamble, Ally!\n",
      "\n",
      "Failed to get player Gamble, Ally!\n",
      "\n",
      "Failed to get player Wilson-Talmadge, Kennedy!\n",
      "\n",
      "Failed to get player Pearson, Caroline!\n",
      "\n",
      "Failed to get player Carter, Annie!\n",
      "\n",
      "Failed to get player Watts, Maddie!\n",
      "\n",
      "Failed to get player McGinley, Megan!\n",
      "\n",
      "Failed to get player Watts, Maddie!\n",
      "\n",
      "Failed to get player McGinley, Megan!\n",
      "\n",
      "Failed to get player Williams, Kayla!\n",
      "\n",
      "Failed to get player Mattson, Sidney!\n",
      "\n",
      "Failed to get player Brueggeman, Paige!\n",
      "\n",
      "Failed to get player Smith, Maggie!\n",
      "\n",
      "Failed to get player Vail, Jordan!\n",
      "\n",
      "Failed to get player Bettenga, Grace!\n",
      "\n",
      "Failed to get player Ziegler, Steph!\n",
      "\n",
      "Failed to get player Tepavac, Teodora!\n",
      "\n",
      "Failed to get player Merseli, Tamara!\n",
      "\n",
      "Failed to get player Vail, Jordan!\n",
      "\n",
      "Failed to get player Brekke, Tamika!\n",
      "\n",
      "Failed to get player Fraase, Alivia!\n",
      "\n",
      "Failed to get player Bockrath, Carolyn!\n",
      "\n",
      "Failed to get player Clay, Amber!\n",
      "\n",
      "Failed to get player Wesley, Vanessa!\n",
      "\n",
      "Failed to get player Petersen, Ellie!\n",
      "\n",
      "Failed to get player Hartman, Brianna!\n",
      "\n",
      "Failed to get player Wortman, Kennedy!\n",
      "\n",
      "Failed to get player Alexander, Avery!\n",
      "\n",
      "Failed to get player Hembree, Hallie!\n",
      "\n",
      "Failed to get player Gearon, Rachel!\n",
      "\n",
      "Failed to get player Reyer, Victoria!\n",
      "\n",
      "Failed to get player Scott, Jackie!\n",
      "\n",
      "Failed to get player Streetar, Alicia!\n",
      "\n",
      "Failed to get player Ramich, Carley!\n",
      "\n",
      "Failed to get player Johnson, Arika!\n",
      "\n",
      "Failed to get player Knight, Sami!\n",
      "\n",
      "Failed to get player Scott, Jackie!\n",
      "\n",
      "Failed to get player Knight, Sami!\n",
      "\n",
      "Failed to get player Witt, Ashley!\n",
      "\n",
      "Failed to get player Shashack, Katie!\n",
      "\n",
      "Failed to get player Tallman, Megan!\n",
      "\n",
      "Failed to get player Fogg, Samantha!\n",
      "\n",
      "Failed to get player Badowski, Ally!\n",
      "\n",
      "Failed to get player Leish, Jessica!\n",
      "\n",
      "Failed to get player Badowski, Ally!\n",
      "\n",
      "Failed to get player Lasry, Nitzan!\n",
      "\n",
      "Failed to get player Parker, Alexis!\n",
      "\n",
      "Failed to get player Johnson, Lexi!\n",
      "\n",
      "Failed to get player Westenhofer, Abigail!\n",
      "\n",
      "Failed to get player Asdell, Elizabeth!\n",
      "\n",
      "Failed to get player Fields, Kenzie!\n",
      "\n",
      "Failed to get player Uke, Jessica!\n",
      "\n",
      "Failed to get player Webb, Sheridan!\n",
      "\n",
      "Failed to get player Knight, Nicole!\n",
      "\n",
      "Failed to get player Holmes, Shelby!\n",
      "\n",
      "Failed to get player Knight, Nicole!\n",
      "\n",
      "Failed to get player Petersen, Lauren!\n",
      "\n",
      "Failed to get player Turner, Madison!\n",
      "\n",
      "Failed to get player Murphy, Anna!\n",
      "\n",
      "Failed to get player Weeks, Alden!\n",
      "\n",
      "Failed to get player May, Carlisa!\n",
      "\n",
      "Failed to get player Fields, Kenzie!\n",
      "\n",
      "Failed to get player Svorinic, Victoria!\n",
      "\n",
      "Failed to get player Spriggs, Tyler!\n",
      "\n",
      "Failed to get player Dahlke, Kendra!\n",
      "\n",
      "Failed to get player Hernandez, Mackenzie!\n",
      "\n",
      "Failed to get player Watanabe, Sara!\n",
      "\n",
      "Failed to get player Larson, Laura!\n",
      "\n",
      "Failed to get player Snuka, Penina!\n",
      "\n",
      "Failed to get player Spriggs, Tyler!\n",
      "\n",
      "Failed to get player Jacobson, Mckenzie!\n",
      "\n",
      "Failed to get player Paige, Whipple!\n",
      "\n",
      "Failed to get player Ua, Malina!\n",
      "\n",
      "Failed to get player Watanabe, Sara!\n",
      "\n",
      "Failed to get player Owen, Riley!\n",
      "\n",
      "Failed to get player Cernjanski, Jovana!\n",
      "\n",
      "Failed to get player Guidotti, Belissa!\n",
      "\n",
      "Failed to get player Hopkins, Kassidy!\n",
      "\n",
      "Failed to get player Martin, Sydnee!\n",
      "\n",
      "Failed to get player Marin, Veronica!\n",
      "\n",
      "Failed to get player Robinson, Mya!\n",
      "\n",
      "Failed to get player Lindberg, Taylor!\n",
      "\n",
      "Failed to get player Mesa, Maritza!\n",
      "\n",
      "Failed to get player Gillard, Daisha!\n",
      "\n",
      "Failed to get player Mesa, Maritza!\n",
      "\n",
      "Failed to get player Robinson, Mya!\n",
      "\n",
      "Failed to get player Beirman, Danielle!\n",
      "\n",
      "Failed to get player Maier, Arilyn!\n",
      "\n",
      "Failed to get player Stocking, Jessica!\n",
      "\n",
      "Failed to get player Tait, Jennifer!\n",
      "\n",
      "Failed to get player Linxwiler, Madison!\n",
      "\n",
      "Failed to get player Jackson, Courtney!\n",
      "\n",
      "Failed to get player Maier, Arilyn!\n",
      "\n",
      "Failed to get player Hall, Grayson!\n",
      "\n",
      "Failed to get player Murray, Faith!\n",
      "\n",
      "Failed to get player Holdford, Anna Grace!\n",
      "\n",
      "Failed to get player Harty, Rachel!\n",
      "\n",
      "Failed to get player Stocking, Jessica!\n",
      "\n",
      "Failed to get player Hudson, Brianna!\n",
      "\n",
      "Failed to get player Egu, Christine!\n",
      "\n",
      "Failed to get player Jularic, Antonela!\n",
      "\n",
      "Failed to get player Dominguez, Ashley!\n",
      "\n",
      "Failed to get player Vaughan, Allison!\n",
      "\n",
      "Failed to get player Vaughan, Allison!\n",
      "\n",
      "Failed to get player Dominguez, Ashley!\n",
      "\n",
      "Failed to get player Gonzales, Amanda!\n",
      "\n",
      "Failed to get player Chatham, Natalya!\n",
      "\n",
      "Failed to get player Kiefer, Kasey!\n",
      "\n",
      "Failed to get player Chatham, Natalya!\n",
      "\n",
      "Failed to get player Pick, Lauren!\n",
      "\n",
      "Failed to get player Keisle, Mckenzie!\n",
      "\n",
      "Failed to get player Budinich, Olivia!\n",
      "\n",
      "Failed to get player Roberts, Sam!\n",
      "\n",
      "Failed to get player Kinnan, Callan!\n",
      "\n",
      "Failed to get player Gillcrist, Marie!\n",
      "\n",
      "Failed to get player Connors, Sage!\n",
      "\n",
      "Failed to get player Roberts, Sam!\n",
      "\n",
      "Failed to get player Montgomery, Kelsey!\n",
      "\n",
      "Failed to get player Gillcrist, Marie!\n",
      "\n",
      "Failed to get player Keisle, Mckenzie!\n",
      "\n",
      "Failed to get player Pick, Lauren!\n",
      "\n",
      "Failed to get player Leverenz, Lauren!\n",
      "\n",
      "Failed to get player Rivas, Camila!\n",
      "\n",
      "Failed to get player Gagen, Ashley!\n",
      "\n",
      "Failed to get player Rivas, Camila!\n",
      "\n",
      "Failed to get player Haak, Katia!\n",
      "\n",
      "Failed to get player Oh, Maddie!\n",
      "\n",
      "Failed to get player Loftus, Monica!\n",
      "\n",
      "Failed to get player Ejele, Maryann!\n",
      "\n",
      "Failed to get player Haak, Katia!\n",
      "\n",
      "Failed to get player Backus, Jenny!\n",
      "\n",
      "Failed to get player Long, Mackenzie!\n",
      "\n",
      "Failed to get player Leverenz, Lauren!\n",
      "\n",
      "Failed to get player Tingelhoff, Jade!\n",
      "\n",
      "Failed to get player Muldrow, Maya!\n",
      "\n",
      "Failed to get player Bowser, Cortnee!\n",
      "\n",
      "Failed to get player Wolf, Sabrina!\n",
      "\n",
      "Failed to get player Shepherd, Parker!\n",
      "\n",
      "Failed to get player Eller, Maya!\n",
      "\n",
      "Failed to get player Tingelhoff, Jade!\n",
      "\n",
      "Failed to get player Nolan, Carly!\n",
      "\n",
      "Failed to get player Wolf, Sabrina!\n",
      "\n",
      "Failed to get player Kissel, Megan!\n",
      "\n",
      "Failed to get player Nolan, Carly!\n",
      "\n",
      "Failed to get player Cabarkapa, Dasha!\n",
      "\n",
      "Failed to get player Chalk, Hannah!\n",
      "\n",
      "Failed to get player Stieber, Stephanie!\n",
      "\n",
      "Failed to get player Berry, Bonaire!\n",
      "\n",
      "Failed to get player Polak, Megan!\n",
      "\n",
      "Failed to get player Jennison, Katie!\n",
      "\n",
      "Failed to get player Donaldson, Jessica!\n",
      "\n",
      "Failed to get player Bennett, Kelly!\n",
      "\n",
      "Failed to get player Stieber, Stephanie!\n",
      "\n",
      "Failed to get player Berry, Bonaire!\n",
      "\n",
      "Failed to get player Brantley, Mariah!\n",
      "\n",
      "Failed to get player Develle, Emily!\n",
      "\n",
      "Failed to get player Weakland, Emma!\n",
      "\n",
      "Failed to get player Skelton, Carlie!\n",
      "\n",
      "Failed to get player Vaucher, Marion!\n",
      "\n",
      "Failed to get player Rosario, Lourdes!\n",
      "\n",
      "Failed to get player Wu, Phoebe!\n",
      "\n",
      "Failed to get player Rosario, Lourdes!\n",
      "\n",
      "Failed to get player Rudnik, Alexis!\n",
      "\n",
      "Failed to get player Fey, Keaupono!\n",
      "\n",
      "Failed to get player Gray, Brianna!\n",
      "\n",
      "Failed to get player Schroll, Kelsey!\n",
      "\n",
      "Failed to get player Hill, Brieanna!\n",
      "\n",
      "Failed to get player Tobison, Stephanie!\n",
      "\n",
      "Failed to get player Piper, Jade!\n",
      "\n",
      "Failed to get player Piper, Jade!\n",
      "\n",
      "Failed to get player Perry, Alexa!\n",
      "\n",
      "Failed to get player Hill, Brieanna!\n",
      "\n",
      "Failed to get player Perry, Alexa!\n",
      "\n",
      "Failed to get player Becerra, Victoria!\n",
      "\n",
      "Failed to get player Weimer, Emily!\n",
      "\n",
      "Failed to get player Lerille, Sydney!\n",
      "\n",
      "Failed to get player Coffey, Kaitlyn!\n",
      "\n",
      "Failed to get player Foote, Casey!\n",
      "\n",
      "Failed to get player Moussaid, Lauren!\n",
      "\n",
      "Failed to get player Heishman, Taylor!\n",
      "\n",
      "Failed to get player Shaw, Denisha!\n",
      "\n",
      "Failed to get player Zumbach, Sara!\n",
      "\n",
      "Failed to get player Kemp, Katie!\n",
      "\n",
      "Failed to get player Ames, Austyn!\n",
      "\n",
      "Failed to get player Moussaid, Lauren!\n",
      "\n",
      "Failed to get player Pippus, Heather!\n",
      "\n",
      "Failed to get player Foote, Casey!\n",
      "\n",
      "Failed to get player Pippus, Heather!\n",
      "\n",
      "Failed to get player Cummings, Macy!\n",
      "\n",
      "Failed to get player D'Alessandro, Jenny!\n",
      "\n",
      "Failed to get player Franklin, Amari!\n",
      "\n",
      "Failed to get player Addvensky, Jessica!\n",
      "\n",
      "Failed to get player Elliott, Katelyn!\n",
      "\n",
      "Failed to get player Lewis, Ebony!\n",
      "\n",
      "Failed to get player Giambrone, Adison!\n",
      "\n",
      "Failed to get player Ickes, Emilie!\n",
      "\n",
      "Failed to get player Aguilera, Alexandra!\n",
      "\n",
      "Failed to get player Elliott, Katelyn!\n",
      "\n",
      "Failed to get player Elliott, Katelyn!\n",
      "\n",
      "Failed to get player Myers, Rae!\n",
      "\n",
      "Failed to get player Havel, Paige!\n",
      "\n",
      "Failed to get player Uadiale, Camille!\n",
      "\n",
      "Failed to get player Lindor, Jasmine!\n",
      "\n",
      "Failed to get player Walton, Lily!\n",
      "\n",
      "Failed to get player Wiggins, Megan!\n",
      "\n",
      "Failed to get player Hawkins-Hollingsworth, Te'Borah!\n",
      "\n",
      "Failed to get player Martino, Liz!\n",
      "\n",
      "Failed to get player Wiggins, Megan!\n",
      "\n",
      "Failed to get player Finnerty, Kayla!\n",
      "\n",
      "Failed to get player Meadows, Carena!\n",
      "\n",
      "Failed to get player Meadows, Carena!\n",
      "\n",
      "Failed to get player Johnson, Kori!\n",
      "\n",
      "Failed to get player Cunningham, Erin!\n",
      "\n",
      "Failed to get player Levers, Lacey!\n",
      "\n",
      "Failed to get player McGinn, Sydney!\n",
      "\n",
      "Failed to get player Martini, Sydney!\n",
      "\n",
      "Failed to get player Glover, Sydney!\n",
      "\n",
      "Failed to get player Vecera, Camryn!\n",
      "\n",
      "Failed to get player Burnham, Madelynn!\n",
      "\n",
      "Failed to get player Vecera, Camryn!\n",
      "\n",
      "Failed to get player McGinn, Sydney!\n",
      "\n",
      "Failed to get player Bazelak, Maddie!\n",
      "\n",
      "Failed to get player Whalen, Mariah!\n",
      "\n",
      "Failed to get player MacDonald, Amber!\n",
      "\n",
      "Failed to get player Saunders, Julia!\n",
      "\n",
      "Failed to get player Robbins, Jordan!\n",
      "\n",
      "Failed to get player Blake, Tori!\n",
      "\n",
      "Failed to get player Whalen, Mariah!\n",
      "\n",
      "Failed to get player Nelson, Haleigh!\n",
      "\n",
      "Failed to get player Bates, Kelli!\n",
      "\n",
      "Failed to get player Williams, Tionna!\n",
      "\n",
      "Failed to get player Kriskova, Romana!\n",
      "\n",
      "Failed to get player Williams, Tionna!\n",
      "\n",
      "Failed to get player Deak, Iva!\n",
      "\n",
      "Failed to get player Deak, Iva!\n",
      "\n",
      "Failed to get player Asci, Irem!\n",
      "\n",
      "Failed to get player Guennewig, Carla!\n",
      "\n",
      "Failed to get player Guennewig, Carla!\n",
      "\n",
      "Failed to get player Asci, Irem!\n",
      "\n",
      "Failed to get player Vandegrift, Hannah!\n",
      "\n",
      "Failed to get player Heirakuji, Mia!\n",
      "\n",
      "Failed to get player Rapacz, Izabella!\n",
      "\n",
      "Failed to get player Coundourides, Kyra!\n",
      "\n",
      "Failed to get player Vandegrift, Hannah!\n",
      "\n",
      "Failed to get player Heirakuji, Mia!\n",
      "\n",
      "Failed to get player Azevedo, Julia!\n",
      "\n",
      "Failed to get player Lilliquist, Alexandra!\n",
      "\n",
      "Failed to get player Hansson, Filippa!\n",
      "\n",
      "Failed to get player Fink, Viktoria!\n",
      "\n",
      "Failed to get player Vukosavljevic, Sonja!\n",
      "\n",
      "Failed to get player Fink, Viktoria!\n",
      "\n",
      "Failed to get player Zhao, Mengdi!\n",
      "\n",
      "Failed to get player Hopton, Nicole!\n",
      "\n",
      "Failed to get player Azevedo, Julia!\n",
      "\n",
      "Failed to get player Petranovic, Nina!\n",
      "\n",
      "Failed to get player Magee, Emily!\n",
      "\n",
      "Failed to get player Krepper, Katharina!\n",
      "\n",
      "Failed to get player LaFace, Alyssa!\n",
      "\n",
      "Failed to get player LaFace, Alyssa!\n",
      "\n",
      "Failed to get player Falco, Samantha!\n",
      "\n",
      "Failed to get player Irbe, Rachel!\n",
      "\n",
      "Failed to get player Sutton, Alysa!\n",
      "\n",
      "Failed to get player LaFace, Alyssa!\n",
      "\n",
      "Failed to get player Smith, Jordan!\n",
      "\n",
      "Failed to get player Rajewski, Mallory!\n",
      "\n",
      "Failed to get player Smith, Jordan!\n",
      "\n",
      "Failed to get player Ferguson, Kelly!\n",
      "\n",
      "Failed to get player Rajewski, Mallory!\n",
      "\n",
      "Failed to get player Falco, Samantha!\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/ncaa/raw/2017/team_stats/Penn St..csv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-f775c45951c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mteam_matches_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"combined/game_by_game_{window}_sma_combined\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mmacthes_with_player_info_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"combined/game_by_game_with_players_{window}_sma_combined\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mcombined_output_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"combined/accumulated/{window}_sme_with_players_combined.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         )\n",
      "\u001b[0;32m<ipython-input-75-7981636cf985>\u001b[0m in \u001b[0;36mcombine_with_player\u001b[0;34m(player_input_path, team_stats_paths, team_matches_path, macthes_with_player_info_path, combined_output_path)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteam_stats_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteam_stats_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mdf_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteam_stats_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{alternate_name}.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0mteam_stats_dfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_read\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3-envs/AI/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3-envs/AI/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3-envs/AI/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3-envs/AI/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3-envs/AI/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/ncaa/raw/2017/team_stats/Penn St..csv'"
     ]
    }
   ],
   "source": [
    "window = 10\n",
    "\n",
    "combine_with_player(\n",
    "            player_input_path=data_path.joinpath(f\"combined/player_game_wise_{window}_sma_combined\"),\n",
    "            team_stats_paths=team_stats_paths,\n",
    "            team_matches_path=data_path.joinpath(f\"combined/game_by_game_{window}_sma_combined\"),\n",
    "            macthes_with_player_info_path=data_path.joinpath(f\"combined/game_by_game_with_players_{window}_sma_combined\"),\n",
    "            combined_output_path=data_path.joinpath(f\"combined/accumulated/{window}_sme_with_players_combined.csv\"),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          a  b\n0  abcd2019  5\n1  abcd2018  6\n2  abcd2017  7\n3  abcd2016  8\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [a, b]\n",
       "Index: []"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a</th>\n      <th>b</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'a':[\"abcd2019\", \"abcd2018\", \"abcd2017\", \"abcd2016\"], 'b':[5, 6, 7, 8]})\n",
    "c = df[df.a.str.contains('2020', case=False)]\n",
    "print(df)\n",
    "c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}